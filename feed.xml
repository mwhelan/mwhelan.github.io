<feed xmlns="http://www.w3.org/2005/Atom"><title type="text">michael whelan</title><subtitle type="text">michael whelan</subtitle><id>http://www.michael-whelan.net/</id><updated>2016-07-18T12:40:34+01:00</updated><author><name>Michael Whelan</name><uri>http://www.michael-whelan.net</uri><email>mjmwdev@gmail.com</email></author><generator>Sandra.Snow Atom Generator</generator><link rel="alternate" href="http://www.michael-whelan.net/feed.xml" /><link rel="self" type="text/html" title="michael whelan" href="http://www.michael-whelan.net/feed.xml" /><entry><id>http://www.michael-whelan.net/using-humanizer-with-asp-dotnet-core/</id><title type="text">A Humanizer Display Metadata Provider for ASP .Net Core</title><summary type="html">&lt;p&gt;I have always been a big fan of using a Humanizer model metadata provider in my ASP.Net MVC applications. This means that Humanizer will automatically put spaces into labels for multi-word view model property names rather than the developer having to manually add a lot of data annotation Display attributes to those view model property names. The APIs have changed a little for ASP.Net Core, but the approach is basically the same. &lt;/p&gt;

</summary><published>2016-07-18T07:00:00Z</published><updated>2016-07-18T07:00:00Z</updated><link rel="alternate" href="http://www.michael-whelan.net/using-humanizer-with-asp-dotnet-core/" /><content type="html">&lt;p&gt;I have always been a big fan of using a Humanizer model metadata provider in my ASP.Net MVC applications. This means that Humanizer will automatically put spaces into labels for multi-word view model property names rather than the developer having to manually add a lot of data annotation Display attributes to those view model property names. The APIs have changed a little for ASP.Net Core, but the approach is basically the same. &lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;h2&gt;What it does&lt;/h2&gt;

&lt;p&gt;You can read about the approach for classic MVC in &lt;a href="http://www.mehdi-khalili.com/introducing-humanizer/#what-else"&gt;Mehdi's introductory Humanizer post&lt;/a&gt;. Basically, instead of the &lt;code&gt;ReleaseDate&lt;/code&gt; label:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/humanizer-original.png" alt="VS test runner" /&gt; &lt;/p&gt;

&lt;p&gt;you get the preferable &lt;code&gt;Release Date&lt;/code&gt;, with a space between the words.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/humanizer-after.png" alt="VS test runner" /&gt; &lt;/p&gt;

&lt;h2&gt;How it works&lt;/h2&gt;

&lt;p&gt;Rather than inherit from the DataAnnotationsModelMetadataProvider as you did in classic MVC, with ASP.Net Core you need to implement the &lt;code&gt;IDisplayMetadataProvider&lt;/code&gt; interface from the &lt;code&gt;Microsoft.AspNetCore.Mvc.ModelBinding.Metadata&lt;/code&gt; namespace. The implementation is otherwise very similar:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System.Collections.Generic;
using System.ComponentModel;
using System.ComponentModel.DataAnnotations;
using System.Linq;
using Humanizer;
using Microsoft.AspNetCore.Mvc.ModelBinding.Metadata;

public class HumanizerMetadataProvider : IDisplayMetadataProvider
{
    public void CreateDisplayMetadata(DisplayMetadataProviderContext context)
    {
        var propertyAttributes = context.Attributes;
        var modelMetadata = context.DisplayMetadata;
        var propertyName = context.Key.Name;

        if (IsTransformRequired(propertyName, modelMetadata, propertyAttributes))
        {
            modelMetadata.DisplayName = () =&amp;gt; propertyName.Humanize().Transform(To.TitleCase);
        }
    }

    private static bool IsTransformRequired(string propertyName, DisplayMetadata modelMetadata, IReadOnlyList&amp;lt;object&amp;gt; propertyAttributes)
    {
        if (!string.IsNullOrEmpty(modelMetadata.SimpleDisplayProperty))
            return false;

        if (propertyAttributes.OfType&amp;lt;DisplayNameAttribute&amp;gt;().Any())
            return false;

        if (propertyAttributes.OfType&amp;lt;DisplayAttribute&amp;gt;().Any())
            return false;

        if (string.IsNullOrEmpty(propertyName))
            return false;

        return true;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To wire it up, you configure it in the ConfigureServices method of Startup.cs. You add the custom HumanizerMetadataProvider provider to the ModelMetadataDetailsProviders collection.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;services.AddMvc()
    .AddMvcOptions(m =&amp;gt; m.ModelMetadataDetailsProviders.Add(new HumanizerMetadataProvider()));
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Summary&lt;/h2&gt;

&lt;p&gt;Creating a custom model metadata provider in ASP.Net Core is quite similar to ASP.Net MVC, but the APIs have changed a little bit.&lt;/p&gt;
</content></entry><entry><id>http://www.michael-whelan.net/the-state-of-dotnet-core-testing-today/</id><title type="text">The State of .Net Core Testing Today</title><summary type="html">&lt;p&gt;.Net Core 1.0 has been officially released but the tooling is still in preview. This means that a number of open source testing libraries have been able to release at least alpha support for .Net Core, but it is not always easy to locate and you sometimes have to drill through GitHub issues, stack overflow questions, and NuGet feeds, to find it. Third party tools vendors are finding it particularly difficult to provide .Net Core support while the tooling is in preview and still subject to a lot of change, but TestDriven.Net has a number of promising alpha releases. In this post, I am going to look at the main .Net testing providers, their current support for .Net Core, and how you can get hold of them. &lt;/p&gt;

</summary><published>2016-07-17T07:00:00Z</published><updated>2016-07-17T07:00:00Z</updated><link rel="alternate" href="http://www.michael-whelan.net/the-state-of-dotnet-core-testing-today/" /><content type="html">&lt;p&gt;.Net Core 1.0 has been officially released but the tooling is still in preview. This means that a number of open source testing libraries have been able to release at least alpha support for .Net Core, but it is not always easy to locate and you sometimes have to drill through GitHub issues, stack overflow questions, and NuGet feeds, to find it. Third party tools vendors are finding it particularly difficult to provide .Net Core support while the tooling is in preview and still subject to a lot of change, but TestDriven.Net has a number of promising alpha releases. In this post, I am going to look at the main .Net testing providers, their current support for .Net Core, and how you can get hold of them. &lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;h2&gt;Test Project Configuration&lt;/h2&gt;

&lt;p&gt;The steps to create a test project are a little bit different with .Net Core. You still create it as a class library, but now you must mark it as a .Net Core Application (the &lt;code&gt;netcoreapp1.0&lt;/code&gt; framework in the project.json below).  &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"frameworks": {
    "netcoreapp1.0": {
        "dependencies": {
            "Microsoft.NETCore.App": {
                "type": "platform",
                "version": "1.0.0"
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When using the .Net CLI for testing, unit test projects are actually an application, not a class library.If you forget to make this change, the compiler will tell you that &lt;code&gt;dotnet-test-xunit&lt;/code&gt; (for example) is not compatible with your class library project. &lt;/p&gt;

&lt;p&gt;You must also add a project reference to the application project you are testing in the project.json.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"dependencies": {
    "Specify.Autofac": {
      "target": "project"
    },
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can target both net4xx and netcoreapp simply by adding both frameworks together in your project.json file. When you run dotnet test with multiple framework entries, the system will run all your framework tests, one after the other.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"frameworks": {
    "netcoreapp1.0": {
        "dependencies": {
            "Microsoft.NETCore.App": {
                "type": "platform",
                "version": "1.0.0"
            },
            "System.Linq": "4.1.0"
        },
        "imports": [
            "dnxcore50",
            "portable-net45+win8"
      ]
    },
  "net46": {
    "dependencies": {
    },
    "buildOptions": {
      "define": [
        "Approvals"
      ]
    }
  }
},
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Test Runners&lt;/h2&gt;

&lt;p&gt;Unfortunately, my favourite test runners, ReSharper and NCrunch, do not have support for .Net Core yet. That has meant that we have been stuck with either the console runners or the Visual Studio test runner. Fortunately, things are looking up, with TestDriven.Net providing a flurry of alpha packages. There are still a number of issues to work out - tests just flat out don't run on some of my projects - but it seems to be shaping up quite well and is a great option for those projects that it does work for.&lt;/p&gt;

&lt;h3&gt;TestDriven.Net v4 Alpha&lt;/h3&gt;

&lt;p&gt;&lt;a href="https://twitter.com/jcansdale"&gt;Jamie Cansdale&lt;/a&gt;, the maintainer of the venerable TestDriven.Net, has released a number of alpha versions through the &lt;a href="https://github.com/jcansdale/TestDriven.Net-Issues"&gt;TestDriven.Net-Issues project&lt;/a&gt; on his GitHub. The releases consist of .zip files that contain an executable for installing TestDriven.Net as a Visual Studio add-in.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/test-dotnet-core-tdnet.png" alt="VS test runner" /&gt;&lt;/p&gt;

&lt;p&gt;As far as I can tell, the latest release, at the time of writing, is v4.0.3267-alpha. You can find it in &lt;a href="https://github.com/jcansdale/TestDriven.Net-Issues/issues/8"&gt;issue 8&lt;/a&gt;, but you should check any new issues for more recent releases.&lt;/p&gt;

&lt;h3&gt;Console Runners&lt;/h3&gt;

&lt;p&gt;The various test frameworks implement the &lt;a href="https://docs.microsoft.com/en-us/dotnet/articles/core/tools/test-protocol"&gt;.Net Core test protocol&lt;/a&gt; to provide test runners, which allow tests to be run by the Visual Studio test runner or from the command line. &lt;/p&gt;

&lt;p&gt;To run tests from the command line, open a command prompt or PowerShell command window. In the window, navigate to the folder containing the source code of your test project. To run the .Net CLI test runner, type &lt;code&gt;dotnet test&lt;/code&gt;, as shown below:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; dotnet test
xUnit.net .NET CLI test runner (64-bit .NET Core win10-x64)
  Discovering: MyFirstDotNetCoreTests
  Discovered:  MyFirstDotNetCoreTests
  Starting:    MyFirstDotNetCoreTests
    MyFirstDotNetCoreTests.Class1.FailingTest [FAIL]
      Assert.Equal() Failure
      Expected: 5
      Actual:   4
      Stack Trace:
        C:\Samples\MyFirstDotNetCoreTests\src\MyFirstDotNetCoreTests\Class1.cs(16,0): at MyFirstDotNetCoreTests.Class1.FailingTest()
  Finished:    MyFirstDotNetCoreTests
=== TEST EXECUTION SUMMARY ===
   MyFirstDotNetCoreTests  Total: 2, Errors: 0, Failed: 1, Skipped: 0, Time: 0.167s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will kick off the tests using whichever runner is specified in the &lt;code&gt;testRunner&lt;/code&gt; node in project.json.&lt;/p&gt;

&lt;h3&gt;Run tests in Visual Studio&lt;/h3&gt;

&lt;p&gt;The same NuGet package which allows you to run tests from the console also allows you to run tests from within Visual Studio. Show the Test Explorer window by choosing Test &gt; Windows &gt; Test Explorer. The Test Explorer window will show inside Visual Studio, and your test should be visible (if they're not, try building your project to kick off the test discovery process). &lt;/p&gt;

&lt;p&gt;If you click the Run All link in the Test Explorer window, it will run your tests and show you success and failure. You can click on an individual test result to get failure information as well as stack trace information:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/test-dotnet-core-vs-runner.png" alt="VS test runner" /&gt;&lt;/p&gt;

&lt;h3&gt;ReSharper&lt;/h3&gt;

&lt;p&gt;ReSharper does not have test runner support for .Net Core yet. &lt;/p&gt;

&lt;h3&gt;NCrunch&lt;/h3&gt;

&lt;p&gt;NCrunch does not have test runner support for .Net Core yet. Remco Mulder, NCrunch's creator, has a useful explanation &lt;a href="https://ncrunch.uservoice.com/forums/245203-feature-requests/suggestions/8065623-support-dnx-projects"&gt;here&lt;/a&gt; on the difficulties that tool vendors face with the ongoing changes to tooling.&lt;/p&gt;

&lt;h2&gt;Test Frameworks&lt;/h2&gt;

&lt;h3&gt;xUnit&lt;/h3&gt;

&lt;p&gt;xUnit has beta support for .Net Core. In your project.json, you need to set the &lt;code&gt;testRunner&lt;/code&gt; to &lt;code&gt;xunit&lt;/code&gt; and add dependencies for xUnit and the dotnet-test-xunit console runner.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"testRunner": "xunit",
"dependencies": {
    "xunit": "2.2.0-beta2-build3300",
    "dotnet-test-xunit": "2.2.0-preview2-build1029"
},
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using the NuGet Package Management Console:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Install-Package xunit -Pre
Install-Package dotnet-test-xunit -Pre
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;NUnit&lt;/h3&gt;

&lt;p&gt;NUnit also has beta support for .Net Core. In your project.json, you need to set the &lt;code&gt;testRunner&lt;/code&gt; to &lt;code&gt;nunit&lt;/code&gt; and add dependencies for NUnit and the dotnet-test-nunit console runner.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"testRunner": "nunit",
"dependencies": {
    "NUnit": "3.4.1",
    "dotnet-test-nunit": "3.4.0-beta-1"
},
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using the NuGet Package Management Console:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Install-Package Nunit
Install-Package dotnet-test-nunit -Pre
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;MsTest&lt;/h3&gt;

&lt;p&gt;Microsoft's own MsTest also has support for .Net Core. In your project.json, you need to set the &lt;code&gt;testRunner&lt;/code&gt; to &lt;code&gt;mstest&lt;/code&gt; and add dependencies for MSTest.TestFramework and the dotnet-test-mstest console runner.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"testRunner": "mstest",
"dependencies": {
    "MSTest.TestFramework": "1.0.0-preview",
    "dotnet-test-mstest": "1.0.1-preview"
},
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using the NuGet Package Management Console:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Install-Package MSTest.TestFramework -Pre
Install-Package dotnet-test-mstest -Pre
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;BDDfy&lt;/h3&gt;

&lt;p&gt;BDDfy, from TestStack - the simplest BDD framework to use, customize and extend - has full support for .Net Core.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Install-Package TestStack.BDDfy
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Fixie&lt;/h3&gt;

&lt;p&gt;As described in the &lt;a href="https://github.com/fixie/fixie/wiki"&gt;Project Roadmap&lt;/a&gt;, Fixie 2.x is being actively developed on the dev branch to support .NET Core. Fixie itself should leverage .NET Core, and it should allow testing of projects that leverage .NET Core. &lt;/p&gt;

&lt;p&gt;For more detailed progress and discussion on .NET Core, see &lt;a href="https://github.com/fixie/fixie/issues/145"&gt;Issue #145 - Support .NET Core&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;One of the items on the roadmap is to publish a prerelease NuGet package of 2.x for initial round of feedback but, as far as I can tell, that has not been released yet.&lt;/p&gt;

&lt;h2&gt;Mocking Frameworks&lt;/h2&gt;

&lt;p&gt;Most of the mocking frameworks depend on Castle.Core, which itself currently has alpha support for .Net Core. &lt;/p&gt;

&lt;h3&gt;NSubstitute&lt;/h3&gt;

&lt;p&gt;If you go to nuget.org, you will find that the latest NSubstitute package is version 1.10.0 from March and does not have support for .Net Core. However, there is actually an unlisted beta package of version 2.0 with support for .Net Core that is published to nuget.org and just not visible. &lt;/p&gt;

&lt;p&gt;You can install the package via the NuGet CLI with the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Install-Package NSubstitute -Version 2.0.0-beta -Pre
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or you can just add these references to the dependencies node of your project.json. Note that you also need to add a reference to System.Diagnostics.TraceSource.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"NSubstitute": "2.0.0-alpha003",
"System.Diagnostics.TraceSource": "4.0.0",
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can follow the progress of NSubstitute 2.0 on this &lt;a href="https://github.com/nsubstitute/NSubstitute/pull/197"&gt;GitHub issue&lt;/a&gt; or on &lt;a href="https://github.com/alexandrnikitin/NSubstitute/commits/Issue192_NetCore_Project"&gt;Alexandr Nikitin's branch&lt;/a&gt;. &lt;/p&gt;

&lt;h3&gt;FakeItEasy&lt;/h3&gt;

&lt;p&gt;FakeItEasy also don't have a package with .Net Core support officially published on NuGet, but you can access the alpha version of v2.3, with support for .Net Core, on an appveyor NuGet feed:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;https://ci.appveyor.com/nuget/fakeiteasy-jeremymeng
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To access this from your solution, just add this reference as a NuGet package source in Visual Studio and add a NuGet.config to the root of your solution like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;?xml version="1.0" encoding="utf-8"?&amp;gt;
&amp;lt;configuration&amp;gt;
  &amp;lt;packageSources&amp;gt;
    &amp;lt;add key="api.nuget.org" value="https://api.nuget.org/v3/index.json" /&amp;gt;
    &amp;lt;add key="appveyor FakeItEasy" value="https://ci.appveyor.com/nuget/fakeiteasy-jeremymeng" /&amp;gt;
  &amp;lt;/packageSources&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And add a reference to the latest version (2.2.0-coreclr-alpha30 at the time of writing) in the dependencies node of project.json.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"FakeItEasy": "2.2.0-coreclr-alpha30",
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can follow the progress of this release on this &lt;a href="https://github.com/FakeItEasy/FakeItEasy/issues/531"&gt;GitHub issues page&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;Moq&lt;/h3&gt;

&lt;p&gt;Moq has an alpha release published to NuGet.org with support for .Net Core:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Install-Package Moq -Pre
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And, like NSubstitute, it seems you also need to add a reference to System.Diagnostics.TraceSource in your project.json. You can read more about that on &lt;a href="http://stackoverflow.com/questions/37288385/moq-netcore-failing-for-net-core-rc2"&gt;stack overflow&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"moq.netcore": "4.6.25-alpha",
"System.Diagnostics.TraceSource": "4.0.0"
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Assertion Frameworks&lt;/h2&gt;

&lt;p&gt;&lt;a href="http://www.fluentassertions.com/"&gt;Fluent Assertions&lt;/a&gt; and &lt;a href="https://shouldly.readthedocs.io/en/latest/"&gt;Shouldly&lt;/a&gt; both have full support for .Net Core.&lt;/p&gt;

&lt;h2&gt;Other Testing Libraries&lt;/h2&gt;

&lt;p&gt;As far as I can tell, &lt;a href="http://approvaltests.com/"&gt;ApprovalTests&lt;/a&gt; does not have support for .Net Core yet.&lt;/p&gt;

&lt;h2&gt;Summary&lt;/h2&gt;

&lt;p&gt;.Net Core 1.0 has been officially released but the tooling is still in preview. This means that a number of open source testing libraries have been able to release at least alpha support for .Net Core, but it is not always easy to locate. In this post, I have looked at the main .Net testing providers, their current support for .Net Core, and how you can get hold of them.&lt;/p&gt;
</content></entry><entry><id>http://www.michael-whelan.net/replacing-appdomain-in-dotnet-core/</id><title type="text">Replacing AppDomain in .Net Core</title><summary type="html">&lt;p&gt;In the move to .Net Core, Microsoft decided to discontinue certain technologies because they were deemed to be problematic. AppDomain was one of those that did not make the cut. While AppDomains have been discontinued, some of their functionality is still being provided. It is quite hard to find those features though, as they are spread across multiple NuGet packages and there is very little documentation at this stage. Issues on github are the best source of information, but there has been a high churn of APIs in this area and a lot of those discussions and APIs are out-of-date. If you have been hunting around for these features then I hope the code samples here will at least provide you with a good starting point and some clues as to where to find related features.&lt;/p&gt;

</summary><published>2016-07-07T07:00:00Z</published><updated>2016-07-07T07:00:00Z</updated><link rel="alternate" href="http://www.michael-whelan.net/replacing-appdomain-in-dotnet-core/" /><content type="html">&lt;p&gt;In the move to .Net Core, Microsoft decided to discontinue certain technologies because they were deemed to be problematic. AppDomain was one of those that did not make the cut. While AppDomains have been discontinued, some of their functionality is still being provided. It is quite hard to find those features though, as they are spread across multiple NuGet packages and there is very little documentation at this stage. Issues on github are the best source of information, but there has been a high churn of APIs in this area and a lot of those discussions and APIs are out-of-date. If you have been hunting around for these features then I hope the code samples here will at least provide you with a good starting point and some clues as to where to find related features.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;h2&gt;Replacing AppDomain Unload event&lt;/h2&gt;

&lt;p&gt;In .Net classic, it could be quite useful to run code in the AppDomain Unload event, especially if you wanted to perform some actions after all of your tests had completed.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;System.AppDomain.CurrentDomain.DomainUnload += (sender, e) =&amp;gt; {
    InvokeBatchProcessors();
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are no AppDomains in .Net Core. Instead, we can use the AssemblyLoadContext, which is part of the System.Runtime.Loader library:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;System.Runtime.Loader.AssemblyLoadContext.Default.Unloading += context =&amp;gt; InvokeBatchProcessors();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At the time of writing, the current version of System.Runtime.Loader package is 4.0, which you include in your project.json with this entry.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"System.Runtime.Loader": "4.0.0",   
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Replacing AppDomain.GetAssemblies&lt;/h2&gt;

&lt;p&gt;In .Net classic, you could get all of the referenced assemblies from AppDomain.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;AppDomain.CurrentDomain.GetAssemblies();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I really struggled to figure out how to do this in .Net Core. Up until RC1, you were able to use the LibraryManager from the Microsoft.Extensions.PlatformAbstractions package to do it, but that functionality was either removed or moved somewhere else for RC2. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;return libraryManager.GetReferencingLibraries("Specify")
    .SelectMany(a =&amp;gt; a.Assemblies)
    .Select(Assembly.Load);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;One way to do it now, is with the DependencyContext from the Microsoft.Extensions.DependencyModel package. You have to load each assembly and use the new AssemblyName class. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static IEnumerable&amp;lt;Assembly&amp;gt; GetReferencingAssemblies(string assemblyName)
{
    var assemblies = new List&amp;lt;Assembly&amp;gt;();
    var dependencies = DependencyContext.Default.RuntimeLibraries;
    foreach (var library in dependencies)
    {
        if (IsCandidateLibrary(library, assemblyName))
        {
            var assembly = Assembly.Load(new AssemblyName(library.Name));
            assemblies.Add(assembly);
        }
    }
    return assemblies;
}

private static bool IsCandidateLibrary(RuntimeLibrary library, assemblyName)
{
    return library.Name == (assemblyName)
        || library.Dependencies.Any(d =&amp;gt; d.Name.StartsWith(assemblyName));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The DependencyContext.Default has two properties, RuntimeLibraries and CompileLibraries, which both appear to provide the same list of libraries. I'm sure there is a difference between them but at this stage I am not sure what that difference is.&lt;/p&gt;

&lt;p&gt;The current version of Microsoft.Extensions.DependencyModel is 1.0:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"Microsoft.Extensions.DependencyModel": "1.0.0"
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Get All Types from AppDomain&lt;/h2&gt;

&lt;p&gt;If you were getting all the assemblies from the AppDomain, chances are you were wanting to retrieve the types in those assemblies matching a certain query. Using an AppDomain, you could do that like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;return AppDomain.CurrentDomain
    .GetAssemblies()
    .SelectMany(assembly =&amp;gt; assembly.GetExportedTypes());
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It is pretty similar with .Net Core. Again, using the Microsoft.Extensions.DependencyModel library and the GetReferencingAssemblies method from the previous example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;return GetReferencingLibraries("Specify")
    .SelectMany(assembly =&amp;gt; assembly.ExportedTypes);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Assembly now has an ExportedTypes method instead of GetExportedTypes.&lt;/p&gt;

&lt;h2&gt;Creating a Polyfill&lt;/h2&gt;

&lt;p&gt;As I described in my &lt;a href="http://www.michael-whelan.net/porting-dotnet-framework-library-to-dotnet-core/"&gt;previous post&lt;/a&gt;, when porting your code to .Net Core you might like to include a polyfill for missing functionality, so that your code can interact with both implementations seamlessly. A polyfill for AppDomain.CurrentDomain.GetAssemblies would look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class AppDomain
{
    public static AppDomain CurrentDomain { get; private set; }

    static AppDomain()
    {
        CurrentDomain = new AppDomain();
    }

    public Assembly[] GetAssemblies()
    {
        var assemblies = new List&amp;lt;Assembly&amp;gt;();
        var dependencies = DependencyContext.Default.RuntimeLibraries;
        foreach (var library in dependencies)
        {
            if (IsCandidateCompilationLibrary(library))
            {
                var assembly = Assembly.Load(new AssemblyName(library.Name));
                assemblies.Add(assembly);
            }
        }
        return assemblies.ToArray();
    }

    private static bool IsCandidateCompilationLibrary(RuntimeLibrary compilationLibrary)
    {
        return compilationLibrary.Name == ("Specify")
            || compilationLibrary.Dependencies.Any(d =&amp;gt; d.Name.StartsWith("Specify"));
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Summary&lt;/h2&gt;

&lt;p&gt;While AppDomains have been discontinued, for the time being at least, some of their functionality is still being provided. It is quite hard to find those features as they are spread across multiple NuGet packages and there is very little documentation at this stage. Issues on github are the best source of information, but there has been a high churn of APIs in this area and a lot of those discussions and APIs are out-of-date. If you have been hunting around for these features then I hope the code samples here will at least provide you with a good starting point and some clues as to where to find related features.&lt;/p&gt;
</content></entry><entry><id>http://www.michael-whelan.net/porting-dotnet-framework-library-to-dotnet-core/</id><title type="text">Porting a .Net Framework Library to .Net Core</title><summary type="html">&lt;p&gt;I have recently been involved with porting a couple of open source frameworks to .Net Core. It's a brave new world, with lots of new things to discover and learn. In this post I am going to outline the process I've followed to convert my code and a few of the things I've learned along the way. Hopefully, this post will shed some light on the process if you are looking to port your .Net Framework code to .Net Core. Special thanks to &lt;a href="https://twitter.com/JakeGinnivan"&gt;Jake Ginnivan&lt;/a&gt; who, as always, was a font of knowledge on all things programming during the porting exercises!&lt;/p&gt;

</summary><published>2016-07-04T07:00:00Z</published><updated>2016-07-04T07:00:00Z</updated><link rel="alternate" href="http://www.michael-whelan.net/porting-dotnet-framework-library-to-dotnet-core/" /><content type="html">&lt;p&gt;I have recently been involved with porting a couple of open source frameworks to .Net Core. It's a brave new world, with lots of new things to discover and learn. In this post I am going to outline the process I've followed to convert my code and a few of the things I've learned along the way. Hopefully, this post will shed some light on the process if you are looking to port your .Net Framework code to .Net Core. Special thanks to &lt;a href="https://twitter.com/JakeGinnivan"&gt;Jake Ginnivan&lt;/a&gt; who, as always, was a font of knowledge on all things programming during the porting exercises!&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;h2&gt;Run the .Net Portability Analyzer&lt;/h2&gt;

&lt;p&gt;Before you even attempt to port your library, you should run the &lt;a href="https://visualstudiogallery.msdn.microsoft.com/1177943e-cfb7-4822-a8a6-e56c7905292b"&gt;.Net Portability Analyzer&lt;/a&gt; on your existing project. This is available as a console application or a Visual Studio plugin. You can access the Visual Studio plugin by right clicking on the project and selecting Analyze -&gt; Analyze Assembly Portability.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/portcore-analyzer-run.png" alt="Run .Net Portability Analyzer" /&gt;&lt;/p&gt;

&lt;p&gt;This will produce a report that provides two useful pieces of information:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;High-level summary&lt;/strong&gt;: The summary gives you a percentage for each of your assemblies, telling you how much of your framework usage is portable to .NET Core. &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;List of non-portable APIs&lt;/strong&gt;: It provides a table that lists all the usages of APIs that arenâ€™t portable. Most usefully, it also includes a list of recommended changes.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/portcore-analyzer-results.png" alt=".Net Portability Analyzer results" /&gt;&lt;/p&gt;

&lt;h2&gt;Run I Can Has .Net Core&lt;/h2&gt;

&lt;p&gt;Another useful analysis tool is the &lt;a href="https://icanhasdot.net/"&gt;I Can Has .Net Core website&lt;/a&gt;. Just upload your project's packages.config, project.json or paket.dependencies files for analysis and it will build a visualisation of the packages and whether .NET Standard versions are available on nuget.org.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/portcore-icanhasdotnetcore.jpg" alt="I Can Has .Net Core" /&gt;&lt;/p&gt;

&lt;h2&gt;Create a new .Net Core class library project&lt;/h2&gt;

&lt;p&gt;The way to "upgrade" a .Net framework project is actually to create a new .Net Core class library and copy the old C# files into it. Assuming you want it to have the same name as the old project, and be in the same folder, you should remove the existing project and rename its folder on the file system so that the new project can be saved to the original location. &lt;/p&gt;

&lt;h2&gt;Add a global.json file&lt;/h2&gt;

&lt;p&gt;You will need to add a &lt;a href="https://docs.microsoft.com/en-us/dotnet/articles/core/tools/global-json"&gt;global.json file&lt;/a&gt; to the solution, which is used to configure the solution as a whole. It includes just two sections, projects and sdk by default.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  "projects": [ "app", "tests" ],
    "sdk": { "version": "1.0.0-preview2-003121" }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The projects property designates which folders contain source code for the solution. The sdk property specifies the version of the DNX (.Net Execution Environment) that Visual Studio will use when opening the solution. (I think DNX might no longer be the correct terminology. .Net Core has been an ever moving target).&lt;/p&gt;

&lt;h2&gt;Add target frameworks to project.json file&lt;/h2&gt;

&lt;p&gt;The frameworks node in project.json specifies the framework versions that the project should be compiled against. In this example, the library will support .Net 4 (net40) and .Net Standard 1.5 (netstandard1.5). Because .Net Core has been decomposed into many modules, this allows you to specify the additional NuGet package dependencies that .Net Core needs (shown in the netstandard1.5 node below).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  "version": "1.0.0-*", 
  "dependencies": {
    "LibLog": "4.2.5",
    "TestStack.BDDfy": "4.3.0"
  },
    "frameworks": {
        "net40": {
          "dependencies": {

          },
            "frameworkAssemblies": {
                "System.Runtime.Serialization": "4.0.0.0",
                "System.Xml": "4.0.0.0"
            }
        },
        "netstandard1.5": {
            "imports": "dnxcore50",
            "buildOptions": {
              "define": [
                "LIBLOG_PORTABLE",
                "NETSTANDARD1_5"
              ]
            },
          "dependencies": {
            "NETStandard.Library": "1.6.0",
            "Microsoft.CSharp": "4.0.1",
            "System.Dynamic.Runtime": "4.0.11"
          }
      }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Fixing missing references for .Net Core&lt;/h2&gt;

&lt;p&gt;When you first build the project, you will most likely get a lot of missing reference exceptions for the .Net Standard target framework (see image below). Note that the project is specified as [ProjectName].NetStandard, Version 1.5. &lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/portcore-missing-references.png" alt="Run .Net Portability Analyzer" /&gt;&lt;/p&gt;

&lt;p&gt;This is quite easy to resolve if this functionality has been ported to one of the many new .Net Core packages. The &lt;a href="http://packagesearch.azurewebsites.net/"&gt;Reverse Package Search&lt;/a&gt; website is a great tool for finding NuGet packages that contain different types. For example, searching for the missing DynamicAttribute from the above error returns the System.Dynamic.Runtime NuGet package. This just needs to be added to the list of dependencies under the netstandard node to resolve the missing reference exception.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/portcore-package-search.png" alt="Run .Net Portability Analyzer" /&gt;&lt;/p&gt;

&lt;h2&gt;GetTypeInfo&lt;/h2&gt;

&lt;p&gt;One of the most common issues is that a lot of the old System.Type reflection functionality has moved to TypeInfo in .Net Core, which you can access through the GetTypeInfo extension method on Type.&lt;/p&gt;

&lt;p&gt;So, instead of &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var members = obj.GetType().GetMembers();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;you would now use:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System.Reflection;
var members = obj.GetType().GetTypeInfo().GetMembers(); 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I am sure that more elegant solutions will come out in time, but for now the way I am handling these differences is with compiler directives. What I have found effective is to create a TypeExtensions class with extension methods on Type. There I replace the various Type properties with methods of the same name, with separate implementations of each method for each supported framework. This, at least, constrains the compiler directives to one place, rather than doing it for every method, and leaves the production code free of compiler directives.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#if NET40
    public static class TypeExtensions
    {
        public static Assembly Assembly(this Type type)
        {
            return type.Assembly;
        }

        public static bool IsValueType(this Type type)
        {
            return type.IsValueType;
        }
    }
#else
    using System.Linq;
    public static class TypeExtensions
    {
        public static Assembly Assembly(this Type type)
        {
            return type.GetTypeInfo().Assembly;   
        }

        public static bool IsValueType(this Type type)
        {
            return type.GetTypeInfo().IsValueType;
        }
    }
#endif
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So, instead of calling the Reflection property, my code now calls my extension method with the same name. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// type.IsValueType;
type.IsValueType();
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Compiler directives or rewrite code&lt;/h2&gt;

&lt;p&gt;It is not ideal to have too many compiler directives in your code. When a feature you were using in the old framework has not been ported to .Net Core you have a choice to make&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Write a new solution for .Net Core and switch between the old and new implementations with compiler directives, or&lt;/li&gt;
&lt;li&gt;Replace the original implementation with a new one that works for both frameworks  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For example, I had some JSON serialization functionality that relied on the JavaScriptSerializer in the System.Web library. This serializer has not been ported to .Net Core, so the short term fix - to get things working - was to use compiler directives to keep the existing soluiton for .Net 4 and provide a new solution for .Net Core. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#if NET40
    using System.Web.Script.Serialization;  
    public class JsonSerializer : ISerializer
    {
        public string Serialize(object obj)
        {
            var serializer = new JavaScriptSerializer();
            string json = serializer.Serialize(obj);

            return new JsonFormatter(json).Format();
        }
    }
#else
    using Newtonsoft.Json;
    public class JsonSerializer : ISerializer
    {
        public string Serialize(object obj)
        {
            return JsonConvert.SerializeObject(obj, Formatting.Indented,
                new JsonSerializerSettings
                {
                    NullValueHandling = NullValueHandling.Ignore,
                    ReferenceLoopHandling = ReferenceLoopHandling.Ignore
                });
        }
    }
#endif
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As more things get ported to .Net Core though, ideally I would hope to remove compiler directives and have a single solution that works for both frameworks, because it really is not ideal to maintain multiple implementations of lots of functionality throughout a codebase. &lt;/p&gt;

&lt;p&gt;Thankfully, the DataContractJsonSerializer has been ported to the System.Runtime.Serialization.Json NuGet package, so I can actually have a single solution that is supported by both frameworks and remove the compiler directives.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System.Runtime.Serialization.Json;
public class JsonSerializer : ISerializer
{
    public string Serialize(object obj)
    {
        var serializer = new DataContractJsonSerializer(obj.GetType());
        string json;
        using (var stream = new MemoryStream())
        {
            serializer.WriteObject(stream, obj);
            json = Encoding.UTF8.GetString(stream.ToArray());
        }

        return new JsonFormatter(json).Format();
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Why didn't I just use Json.Net or ServiceStack.Text to serialize Json? Well, I would if I was building an application, but for a NuGet library I don't want to add a NuGet dependency just for one class of functionality. That might be old world thinking though, given how much of the .Net Framework is now provided as NuGet packages. I may just change my thinking on that but, for now, I still see a distinction between third party packages and .Net packages.&lt;/p&gt;

&lt;h2&gt;Backwards-compatible Polyfills&lt;/h2&gt;

&lt;p&gt;Credit to Jake Ginnivan for this solution. It is actually pretty easy to satisfy the compiler by providing polyfills, or shims, for types that have not been ported to .Net Core. &lt;/p&gt;

&lt;p&gt;For example, Serialization has not been ported, but you might have classes with the Serializable attribute on them. Providing an empty SerializableAttribute class in the System.Runtime.Serialization namespace will satisfy the compiler for your .Net Core code.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#if !NET40
namespace System.Runtime.Serialization
{
    public class SerializableAttribute : Attribute
    {
    }
}
#endif 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Another example I have come across is a polyfill for AppDomain.CurrentDomain, now that AppDomains are no longer supported in .Net Core.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private sealed class AppDomain
{
    public static AppDomain CurrentDomain { get; private set; }

    static AppDomain()
    {
        CurrentDomain = new AppDomain();
    }

    public List&amp;lt;Assembly&amp;gt; GetAssemblies()
    {
        ... // .Net Core functionality here
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Summary&lt;/h2&gt;

&lt;p&gt;There are a lot of exciting new things to learn with .Net Core. Porting your existing code to the framework is a little bit of work - but not too much. The process is quite straightforward with predictable steps, most of which I've hopefully communicated here. The .Net Portability Analyzer is a huge help in enabling you to plan out the conversion beforehand, providing you with a list of issues and - most helpfully - even the solutions to most of the issues. The main area of concern is to provide new solutions for areas of the code that rely on parts of the .Net Framework that have not been ported. Thankfully, this seems to be a reasonably small surface area though, of course, it will depend on each application.&lt;/p&gt;
</content></entry><entry><id>http://www.michael-whelan.net/github-cvs-resumes/</id><title type="text">GitHub CVs / Resumes</title><summary type="html">&lt;p&gt;I just discovered that Github can automatically generate a CV/resume for its users based on the public information in their GitHub account. You have to opt-in by going to their &lt;a href="https://github.com/resume/resume.github.com"&gt;GitHub project&lt;/a&gt; page and starring the project. Check out mine at &lt;a href="http://resume.github.com/?mwhelan"&gt;http://resume.github.com/?mwhelan&lt;/a&gt;. What a clever idea!&lt;/p&gt;

</summary><published>2016-06-02T07:00:00Z</published><updated>2016-06-02T07:00:00Z</updated><link rel="alternate" href="http://www.michael-whelan.net/github-cvs-resumes/" /><content type="html">&lt;p&gt;I just discovered that Github can automatically generate a CV/resume for its users based on the public information in their GitHub account. You have to opt-in by going to their &lt;a href="https://github.com/resume/resume.github.com"&gt;GitHub project&lt;/a&gt; page and starring the project. Check out mine at &lt;a href="http://resume.github.com/?mwhelan"&gt;http://resume.github.com/?mwhelan&lt;/a&gt;. What a clever idea!&lt;/p&gt;

&lt;!--excerpt--&gt;
</content></entry><entry><id>http://www.michael-whelan.net/become-a-fullstack-dotnet-developer-review/</id><title type="text">Review of Pluralsight's Become a Full-stack .Net Developer</title><summary type="html">&lt;p&gt;This weekend was a long weekend in the UK, and my wife was away, so I took the opportunity to work through &lt;a href="http://programmingwithmosh.com/"&gt;Mosh Hamedani's&lt;/a&gt; comprehensive 3 part course on Pluralsight, titled &lt;code&gt;Become a Full-stack .Net Developer&lt;/code&gt;. The three part series aims to take you from a junior .Net developer through to a senior .Net developer by building an ASP.Net MVC 5 application with Entity Framework 6. I really enjoyed the course and thought I would provide a review of it.&lt;/p&gt;

</summary><published>2016-05-30T09:00:00Z</published><updated>2016-05-30T09:00:00Z</updated><link rel="alternate" href="http://www.michael-whelan.net/become-a-fullstack-dotnet-developer-review/" /><content type="html">&lt;p&gt;This weekend was a long weekend in the UK, and my wife was away, so I took the opportunity to work through &lt;a href="http://programmingwithmosh.com/"&gt;Mosh Hamedani's&lt;/a&gt; comprehensive 3 part course on Pluralsight, titled &lt;code&gt;Become a Full-stack .Net Developer&lt;/code&gt;. The three part series aims to take you from a junior .Net developer through to a senior .Net developer by building an ASP.Net MVC 5 application with Entity Framework 6. I really enjoyed the course and thought I would provide a review of it.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;The series is a whopping 14 hours in total, which is really, really long by Pluralsight standards. I would really recommend watching it though and will probably make it suggested watching for my dev teams.&lt;/p&gt;

&lt;p&gt;I did intend to build out the whole thing while I watched but I abandoned that as it would have taken too long (though I would recommend doing that if you are a little less experienced). I revved up the speed to double and watched it like a movie. That's still 7 hours of watching, but well worth it.&lt;/p&gt;

&lt;p&gt;According to Mosh, the series is aimed at the following audiences&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Part 1 =&amp;gt; junior developer
Part 2 =&amp;gt; moving from junior developer to intermediate developer
Part 3 =&amp;gt; moving from intermediate developer to senior developer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hearing that, a lot of experienced devs might move right along, but I'd encourage you to look a bit deeper. While the content is geared towards ASP.Net MVC 5 and Entity Framework 6, the most valuable takeaway is the approach of a senior developer. &lt;/p&gt;

&lt;p&gt;What impressed me the most was Mosh's discipline. He did not let himself get distracted by going off to google to research better solutions, but consistently stuck to the task at hand, OK with doing it a bit dirty at first, confident that with an iterative approach to development he would quickly circle back and remove any technical debt. I can be far less disciplined and find it so easy to get sidetracked on to some research or other yak shaving activity. There's so much to be said for completing the task!&lt;/p&gt;

&lt;p&gt;My favourite part was the third and final part, which gets into architecture and automated testing and such, two topics close to my heart. But the first two are really good value as well. In fact, if Mosh didn't tell you they were aimed at the 3 levels you wouldn't know the difference. It's just that he starts off doing ugly things like newing up the DbContext directly in the controller so that he doesn't distract you with too many concepts at once. But slowly but surely, he refactors things until eventually you have a pretty clean architecture, with repositories/unit of work, and programming to interfaces that are injected with your IoC container. &lt;/p&gt;

&lt;p&gt;The style of the course is similar to pairing with an experienced developer who is just commentating on what he is doing and why. He shows a number of productivity tools, such as ReSharper, Web Essentials and the Productivity Power Tools. In particular, he shows a number of ReSharper shortcuts. Unfortunately, he uses the older IntelliJ shortcuts and I use the Visual Studio ones, but it was no problem to look up their Visual Studio counterparts on &lt;a href="https://www.jetbrains.com/help/resharper/2016.1/Reference__Keyboard_Shortcuts.html"&gt;their website&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;You can view the courses &lt;a href="http://app.pluralsight.com/author/mosh-hamedani"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;You can currently get 6 months of Pluralsight for free if you sign up for an &lt;a href="https://www.visualstudio.com/en-us/products/visual-studio-dev-essentials-vs.aspx"&gt;MSDN Dev Essentials&lt;/a&gt; subscription.&lt;/p&gt;

&lt;p&gt;I think Mosh is a really talented teacher and his style and focus on quality is quite distinctive from other teachers. I can also recommend some of his &lt;a href="https://www.udemy.com/user/moshfeghhamedani/"&gt;Udemy courses&lt;/a&gt; that I've done. You can also find him on his &lt;a href="https://www.youtube.com/channel/UCWv7vMbMWH4-V0ZXdmDpPBA"&gt;youtube channel&lt;/a&gt;.&lt;/p&gt;
</content></entry><entry><id>http://www.michael-whelan.net/bdd-course-london/</id><title type="text">BDD Course in London</title><summary type="html">&lt;p&gt;Last week I had the pleasure of attending Gaspar Nagy's 3-day &lt;a href="http://gasparnagy.com/trainings/specflow/"&gt;BDD course&lt;/a&gt; at Skills Matter's &lt;a href="https://skillsmatter.com/event-space"&gt;CodeNode&lt;/a&gt; in London. I have been doing BDD for over 5 years now, and SpecFlow is not my preferred .Net BDD tool, but I still got a huge amount of value out of the course. Gaspar is very knowledgeable about BDD and I would highly recommend the course, whether you are new to BDD,  a &lt;a href="http://www.specsolutions.eu/news/bddaddict"&gt;BDD addict&lt;/a&gt; like me, or even if you are just struggling with agile.&lt;/p&gt;

</summary><published>2016-05-27T09:00:00Z</published><updated>2016-05-27T09:00:00Z</updated><link rel="alternate" href="http://www.michael-whelan.net/bdd-course-london/" /><content type="html">&lt;p&gt;Last week I had the pleasure of attending Gaspar Nagy's 3-day &lt;a href="http://gasparnagy.com/trainings/specflow/"&gt;BDD course&lt;/a&gt; at Skills Matter's &lt;a href="https://skillsmatter.com/event-space"&gt;CodeNode&lt;/a&gt; in London. I have been doing BDD for over 5 years now, and SpecFlow is not my preferred .Net BDD tool, but I still got a huge amount of value out of the course. Gaspar is very knowledgeable about BDD and I would highly recommend the course, whether you are new to BDD,  a &lt;a href="http://www.specsolutions.eu/news/bddaddict"&gt;BDD addict&lt;/a&gt; like me, or even if you are just struggling with agile.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;I had the good fortune of choosing a seat next to &lt;a href="https://twitter.com/QuestMasterNET"&gt;Dirk Rombauts&lt;/a&gt; on the first day, which resulted in two days of great pair programming, where I learned a lot, including some excellent pairing habits and one trick to double my ReSharper ninja skills!&lt;/p&gt;

&lt;p&gt;It is a wide-ranging course that covers how to gather examples and then turn them into executable specifications, with the implementation focused on ASP.Net MVC and WPF .Net projects. The course covers refining and documenting specification workshop results in Gherkin, feeding Gherkin scenarios into acceptance test driven development with SpecFlow, and advanced concepts for automation and building living documentation systems. The course topics are discussed through examples, demos and hands-on exercises to ensure knowledge that can be used in practice.&lt;/p&gt;

&lt;p&gt;The course started off by looking at the four different areas that make up BDD. So many companies that I see struggling with agile tend to focus primarily on the agile project management area, with perhaps one or two other techniques from the other areas. I think you need to do all four to maximise the benefits of agile.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/specflow-bdd.png" alt="BDD" /&gt;&lt;/p&gt;

&lt;p&gt;The first day was focused on capturing specification workshop results in gherkin, and covered some theory:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Agile testing is not about hunting criminals (finding bugs after development) but more like crime prevention.&lt;/li&gt;
&lt;li&gt;As formality increases, tests and requirements become indistinguishable. At the limit, tests and requirements are equivalent. &lt;em&gt;Equivalence Hypothesis (Martin, Melnik)&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The second day looked at SpecFlow core concepts and ATDD basics, with examples using a WPF pomodoro application, including:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Introduction to the Acceptance Test Driven Development workflow (test first, outside-in)&lt;/li&gt;
&lt;li&gt;Core concepts for (A)TDD: mocking, stubbing, dependency injection&lt;/li&gt;
&lt;li&gt;Domain layer automation (automating under the skin)&lt;/li&gt;
&lt;li&gt;Organizing step definitions&lt;/li&gt;
&lt;li&gt;Sharing state between steps&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The third day looked at advanced test automation topics, using an ASP.Net MVC pomodoro application, including:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Clean and maintainable automation layer&lt;/li&gt;
&lt;li&gt;Dealing with external dependencies&lt;/li&gt;
&lt;li&gt;Flickering scenarios&lt;/li&gt;
&lt;li&gt;UI layer automation (MVC ASP.NET, Driver, PageObject pattern)&lt;/li&gt;
&lt;li&gt;Handling the database&lt;/li&gt;
&lt;li&gt;Challenges of out-of-process testing (with Selenium)&lt;/li&gt;
&lt;li&gt;Organizing step definitions&lt;/li&gt;
&lt;li&gt;Defaults and implicit assumptions of scenarios&lt;/li&gt;
&lt;li&gt;Automapper and SpecFlow.Assist&lt;/li&gt;
&lt;li&gt;Putting it all together: implement new functionality with BDD&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Step Definitions&lt;/h2&gt;

&lt;p&gt;I've spoken with SpecFlow developers who are struggling to organise their step definitions, and I haven't really known what to advise, as it's not an issue with BDDfy, so I was interested to see the best tips for organising them. Gaspar showed a lot of great techniques for organising feature files and step definitions. I particularly liked the suggestion of moving user stories into a feature tree after the sprint was completed. &lt;/p&gt;

&lt;p&gt;I can't help feeling that step definitions are the wrong abstraction for reusability in an automated testing project. There are inherent difficulties from wanting to reuse steps when the two use cases are slightly different, and I would prefer to avoid it altogether.&lt;/p&gt;

&lt;p&gt;Stepping back from tools for a moment, I think that step definitions are just metadata that should just read whatever way makes the most sense for a particular scenario in the living documentation that the users will see, whether it is exactly the same as other steps in the system or slightly different. While I recognise the importance and value of the DRY principle, I don't think it needs to be applied to the step definition itself (as it's just a string on a report).&lt;/p&gt;

&lt;p&gt;What should be reusable is the code inside the step definitions. Things like repositories, builders/object mothers in the Given steps, drivers in the When step, assertions in the Then steps. Why do you need to reuse steps if they only have one line of code, and if that line itself is a useful and reusable abstraction?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public void Given_I_have_5_customers()
{
    Database.Save(CustomerBuilder.CreateListOfSize(5).BuildList());
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Generally, I'm just not comfortable with having my scenario being distributed across multiple feature and step definition files, which I think is inherent in the Gherkin-based approach. I prefer the pure C# solution of having the entire scenario in one file with the class-per-scenario approach (and no feature file):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class ValidEditStudentDetailsScenario : ScenarioFor&amp;lt;MvcControllerDriver, StudentEditStory&amp;gt;
{
    private Student _student;
    private ControllerResultTest&amp;lt;StudentController&amp;gt; _result;

    public void Given_I_am_editing_an_existing_student_with_valid_data()
    {
        Builder&amp;lt;Student&amp;gt;.CreateNew().Persist();
        _student = Container
            .Get&amp;lt;IStudentRepository&amp;gt;()
            .FindById(1);
        _student.FirstMidName = "newFirstName";
    }
    public void When_I_save_the_changes()
    {
        _result = SUT.ExecuteActionFor&amp;lt;StudentController&amp;gt;(c =&amp;gt; c.Edit(_student));
    }

    public void Then_I_am_returned_to_the_student_list()
    {
        _result.ShouldRedirectTo&amp;lt;StudentController&amp;gt;(c =&amp;gt; c.Index(null, null, null, null));
    }

    public void AndThen_the_changes_have_been_saved()
    {
        Container.Get&amp;lt;IStudentRepository&amp;gt;()
            .FindById(1)
            .ShouldBeEquivalentTo(_student);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;The driver pattern&lt;/h2&gt;

&lt;p&gt;Speaking of drivers, Gaspar gave an excellent talk on the driver pattern in relation to the &lt;a href="http://alistair.cockburn.us/Hexagonal+architecture"&gt;hexagonal architecture&lt;/a&gt;. I am quite familiar with how the &lt;a href="http://martinfowler.com/eaaDev/WindowDriver.html"&gt;window driver pattern&lt;/a&gt; is applied to Selenium, in the form of page objects, but Gaspar articulated a more general purpose pattern which extends beyond the UI/windows. &lt;/p&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;There is a lot more I could say about the course. I'm still digesting a lot of the excellent information. My recommendation would be to try to attend it yourself (there are a number of venues around Europe). BDD is by far the best way to deliver software on agile projects that I have come across, and Gaspar Nagy is an excellent guide.&lt;/p&gt;
</content></entry><entry><id>http://www.michael-whelan.net/code-compiling-but-resharper-red/</id><title type="text">Code compiling but ReSharper is red</title><summary type="html">&lt;p&gt;From time-to-time, I have this weird situation with ReSharper and Visual Studios (different versions of both) where my code is compiling, but ReSharper is highlighting some things in red. I think there might be a few different solutions to this problem, and I'll add others here if I come across them. The solution that worked for me this time is just to &lt;a href="http://stackoverflow.com/questions/6040338/everything-compiles-but-resharper-marks-everything-in-red"&gt;delete the .suo files&lt;/a&gt;.&lt;/p&gt;

</summary><published>2015-06-19T09:00:00Z</published><updated>2015-06-19T09:00:00Z</updated><link rel="alternate" href="http://www.michael-whelan.net/code-compiling-but-resharper-red/" /><content type="html">&lt;p&gt;From time-to-time, I have this weird situation with ReSharper and Visual Studios (different versions of both) where my code is compiling, but ReSharper is highlighting some things in red. I think there might be a few different solutions to this problem, and I'll add others here if I come across them. The solution that worked for me this time is just to &lt;a href="http://stackoverflow.com/questions/6040338/everything-compiles-but-resharper-marks-everything-in-red"&gt;delete the .suo files&lt;/a&gt;.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;Another solution that has worked in the past is to clear the ReSharper cache and restart Visual Studio. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ReSharper &amp;gt; Options &amp;gt; Environment &amp;gt; General &amp;gt; Options &amp;gt; General 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Click the Clear Caches button.&lt;/p&gt;
</content></entry><entry><id>http://www.michael-whelan.net/testing-mvc-extending-strongly-typed-navigation/</id><title type="text">Black-Box Testing ASP.Net: Extending Strongly Typed Navigation</title><summary type="html">&lt;p&gt;In a &lt;a href="http://www.michael-whelan.net/testing-mvc-reducing-use-of-magic-strings/"&gt;previous post&lt;/a&gt; in this series, on reducing the use of magic strings, I showed a helper class for creating strongly typed navigation. This lets you derive a URL from a strongly typed controller action by looking up the route in the route table and returning you the same computed URL your application recognises.&lt;/p&gt;

</summary><published>2015-02-22T00:00:00Z</published><updated>2015-02-22T00:00:00Z</updated><link rel="alternate" href="http://www.michael-whelan.net/testing-mvc-extending-strongly-typed-navigation/" /><content type="html">&lt;p&gt;In a &lt;a href="http://www.michael-whelan.net/testing-mvc-reducing-use-of-magic-strings/"&gt;previous post&lt;/a&gt; in this series, on reducing the use of magic strings, I showed a helper class for creating strongly typed navigation. This lets you derive a URL from a strongly typed controller action by looking up the route in the route table and returning you the same computed URL your application recognises.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;Here is a test that illustrates the behaviour. This is a standard situation where the URL simply contains the controller and the action, as well as the ID as a route argument. &lt;code&gt;RouteConfig.RegisterRoutes()&lt;/code&gt; is the method in the application that intialises its route table.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Test]
public void MvcUrlHelper_should_return_correct_route_for_controller_action()
{
    var routes = RouteConfig.RegisterRoutes(new RouteCollection());
    var sut = new MvcUrlHelper(routes);

    sut.GetRelativeUrlFor&amp;lt;StudentController&amp;gt;(x =&amp;gt; x.Details(1))
        .Should().Be("/Student/Details/1");
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Recently, I've had a couple of reasons to extend this class. Firstly, I've been testing applications that use Areas. Secondly, I've needed to be able to pass in additional route values.&lt;/p&gt;

&lt;p&gt;I will start off with the final class and then discuss the additional behaviour:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class MvcUrlHelper
{
    private readonly RouteCollection routeCollection;

    public MvcUrlHelper(RouteCollection routeCollection)
    {
        this.routeCollection = routeCollection;
    }

    public string GetRelativeUrlFor&amp;lt;TController&amp;gt;(Expression&amp;lt;Action&amp;lt;TController&amp;gt;&amp;gt; action, IDictionary&amp;lt;string, object&amp;gt; routeValues = null)
        where TController : Controller
    {
        var requestContext = new RequestContext(FakeHttpContext.Root(), new RouteData());

        // Get controller and action values
        var actionRouteValues = Microsoft.Web.Mvc.Internal.ExpressionHelper.GetRouteValuesFromExpression(action);

        var area = GetArea(typeof(TController));
        if (!string.IsNullOrEmpty(area))
        {
            actionRouteValues.Add("Area", area);
        }

        if (routeValues != null)
        {
            foreach (var v in routeValues) actionRouteValues[v.Key] = v.Value;
        }

        var urlHelper = new UrlHelper(requestContext, this.routeCollection);
        var relativeUrl = urlHelper.RouteUrl(new RouteValueDictionary(actionRouteValues));

        return relativeUrl;
    }

    private static string GetArea(Type controllerType)
    {
        var routeAreaAttributes = controllerType.GetCustomAttributes(typeof(RouteAreaAttribute), true);
        if (routeAreaAttributes.Length &amp;gt; 0)
        {
            var routeArea = (RouteAreaAttribute)(routeAreaAttributes[0]);
            return routeArea.AreaName;
        }

        var nameSpace = controllerType.Namespace;
        if (nameSpace == null)
        {
            return string.Empty;
        }

        const string AreasStartSearchString = "Areas.";
        var areasIndexOf = nameSpace.IndexOf(AreasStartSearchString, StringComparison.Ordinal);
        if (areasIndexOf &amp;lt; 0)
        {
            return string.Empty;
        }

        var areaStart = areasIndexOf + AreasStartSearchString.Length;
        var areaString = nameSpace.Substring(areaStart);
        if (areaString.Contains("."))
        {
            areaString = areaString.Remove(areaString.IndexOf(".", StringComparison.Ordinal));
        }

        return areaString;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Areas&lt;/h2&gt;

&lt;p&gt;The MVC5 Futures &lt;code&gt;ExpressionHelper&lt;/code&gt; class does not return the area in the URL (unless you use its Area attribute). Here is the test that illustrates the behaviour I want, where University is the Area and Student the controller. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[TestMethod]
public void should_return_area_in_url()
{
    var routes = RouteConfig.RegisterRoutes(new RouteCollection());
    var sut = new MvcUrlHelper(routes);
    var result = sut.GetRelativeUrlFor&amp;lt;StudentController&amp;gt;(c =&amp;gt; c.Create());
    result.ShouldBe("/University/Student/Create");
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;GetArea&lt;/code&gt; method tries to find area information by interrogating the controller type. Firstly, it looks for a &lt;code&gt;RouteAreaAttribute&lt;/code&gt; on the class. Secondly, it looks at the namespace to see if it is in the standard Areas namespace, and extracts the Area from the namespace if it is. If this method returns an area then it is added to the actionRouteValues &lt;code&gt;RouteValueDictionary&lt;/code&gt;.&lt;/p&gt;

&lt;h2&gt;Additional Route Values&lt;/h2&gt;

&lt;p&gt;Sometimes, you must provide additional route values that the &lt;code&gt;UrlHelper&lt;/code&gt; class requires to construct a URL. This test shows the adding of an &lt;code&gt;application&lt;/code&gt; route value, with a value of &lt;code&gt;Books&lt;/code&gt;, which is used in the URL.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[TestMethod]
public void should_return_application_in_url()
{
    var sut = new MvcUrlHelper(new RouteRegistrator().RegisterRoutes());
    var application = new Dictionary&amp;lt;string, object&amp;gt; { { "application", "Books" } };
    var result = sut.GetRelativeUrlFor&amp;lt;CollectionsController&amp;gt;(c =&amp;gt; c.Details(23), application);
    Assert.AreEqual("/Editorial/Applications/Books/Collections/Details?collectionId=23", result);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;These additional values are used by UrlHelper in the creation of the full URL to make the test pass.&lt;/p&gt;
</content></entry><entry><id>http://www.michael-whelan.net/testing-mvc-using-aspnet-mvc-view-models-with-selenium-webdriver/</id><title type="text">Black-Box Testing ASP.Net: Using ASP.Net MVC View Models with Selenium WebDriver</title><summary type="html">&lt;p&gt;This post continues the theme of the &lt;a href="http://www.michael-whelan.net/testing-mvc-reducing-use-of-magic-strings/"&gt;previous post&lt;/a&gt;, in looking at how a little knowledge of the inner workings of the MVC application can go a long way to writing less brittle, more maintainable, UI tests with Selenium WebDriver. In this post I am going to look at how we can use the same view model in the test that the application view uses to automate the reading and writing of data from the web page. (It could also be a domain model class, I just prefer to use view models for my views and keep my domain models separate).&lt;/p&gt;

</summary><published>2015-01-04T00:00:00Z</published><updated>2015-01-04T00:00:00Z</updated><link rel="alternate" href="http://www.michael-whelan.net/testing-mvc-using-aspnet-mvc-view-models-with-selenium-webdriver/" /><content type="html">&lt;p&gt;This post continues the theme of the &lt;a href="http://www.michael-whelan.net/testing-mvc-reducing-use-of-magic-strings/"&gt;previous post&lt;/a&gt;, in looking at how a little knowledge of the inner workings of the MVC application can go a long way to writing less brittle, more maintainable, UI tests with Selenium WebDriver. In this post I am going to look at how we can use the same view model in the test that the application view uses to automate the reading and writing of data from the web page. (It could also be a domain model class, I just prefer to use view models for my views and keep my domain models separate).&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;blockquote&gt;
  &lt;p&gt;Some of the sample code is taken straight from &lt;a href="https://github.com/TestStack/TestStack.Seleno"&gt;Seleno&lt;/a&gt;, the Selenium WebDriver browser automation framework from &lt;a href="http://teststack.net/"&gt;TestStack&lt;/a&gt;, and gives you a look under the hood at the sorts of things a UI automation framework does for you. If some of these samples are relevant to the problems you are trying to solve, I encourage you to check out Seleno. It takes care of a lot of the complex infrastructure setup of a Selenium WebDriver project for you, allowing you to get on with the important business of writing specifications for your application. I've produced a working sample on &lt;a href="https://github.com/mwhelan/MvcTestingSamples"&gt;GitHub&lt;/a&gt;, so you should be able to take it, run it, and use some of the code in your own applications if you want to.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2&gt;Input View Model Property into Web Page&lt;/h2&gt;

&lt;p&gt;When you use strongly typed views (with models) and generate HTML for the model properties with expression-based HTML helpers, such as &lt;code&gt;Html.EditorFor()&lt;/code&gt;, MVC will produce controls with predictable names for the properties of the model. This view code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@model ContosoUniversity.ViewModels.CreateStudentForm
...
@Html.EditorFor(model =&amp;gt; model.LastName)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;will produce this HTML:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;input name="LastName" class="text-box single-line" id="LastName" type="text" value="" &amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can leverage this MVC infrastructure in our UI tests to input a model property into a form field. System.Web.Mvc provides the &lt;code&gt;ExpressionHelper.GetExpressionText&lt;/code&gt; method to provide the same control name from the model property that the expression-based HTML helpers provide in the views.&lt;/p&gt;

&lt;p&gt;We can derive a strongly typed base page object from the base page object used in the previous post, where &lt;code&gt;TModel&lt;/code&gt; is the view model class used by that view. The &lt;code&gt;TextBoxFor&lt;/code&gt; method uses ExpressionHelper to derive the name of the control from the model property expression, then uses WebDriver to find the element and populate it with the specified value.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class Page&amp;lt;TModel&amp;gt; : Page
{
    public Page&amp;lt;TModel&amp;gt; TextBoxFor&amp;lt;TField&amp;gt;(Expression&amp;lt;Func&amp;lt;TModel, TField&amp;gt;&amp;gt; field, TField value)
    {
        var name = ExpressionHelper.GetExpressionText(field);

        var element = Host.Browser.FindElement(By.Name(name));
        element.Clear();
        element.SendKeys(value.ToString());

        return this;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we can modify the &lt;code&gt;NewStudentPage&lt;/code&gt; page object to use the strongly typed page object and specify the &lt;code&gt;CreateStudentForm&lt;/code&gt; view model, which is the one that the view uses. The various Input methods are able to enter data into the web page using the appropriate property expression in a strongly typed way. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class NewStudentPage : Page&amp;lt;CreateStudentForm&amp;gt;
{
    public string HeaderTitle
    {
        get
        {
            var header = Host.Browser.FindElement(By.Id("title"));
            return header.Text;
        }
    }

    public NewStudentPage InputLastName(string lastName)
    {
        TextBoxFor(x =&amp;gt; x.LastName, lastName);
        return this;
    }

    public NewStudentPage InputFirstName(string firstName)
    {
        TextBoxFor(x =&amp;gt; x.FirstMidName, firstName);
        return this;
    }

    public NewStudentPage InputEnrollmentDate(DateTime enrollmentDate)
    {
        TextBoxFor(x =&amp;gt; x.EnrollmentDate, enrollmentDate);
        return this;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In keeping with the page object design pattern each method returns the page so that test code can set multiple properties in the fluent style, as you can see from this test.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Test]
public void CanPopulateAFormFieldFromModelProperty()
{
    var student = Builder&amp;lt;CreateStudentForm&amp;gt;
        .CreateNew()
        .Build();
    var newStudentPage = Host.NavigateTo&amp;lt;StudentController, NewStudentPage&amp;gt;(x =&amp;gt; x.Create());

    newStudentPage
        .InputFirstName(student.FirstMidName)
        .InputLastName(student.LastName)
        .InputEnrollmentDate(student.EnrollmentDate);

    Host.Browser.FindElement(By.Id("FirstMidName")).GetAttribute("value").Should().Be(student.FirstMidName);
    Host.Browser.FindElement(By.Id("LastName")).GetAttribute("value").Should().Be(student.LastName);
    Host.Browser.FindElement(By.Id("EnrollmentDate")).GetAttribute("value").Should().Be(student.EnrollmentDate.ToString());
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Input Whole View Model into Web Page&lt;/h2&gt;

&lt;p&gt;To be honest, I strongly dislike this approach of the page object exposing every property of the view model individually. It lends itself to script-style code, with lots of repetitive calls to set each property, obfuscating the meaning of the test. I prefer more of a specification style of test, where each method on the page object is representative of a behaviour of the application (more than likely representative of a single request/response  - a single controller action). This improves the API of the Page Object layer, and makes for a better Domain Specific Language (DSL) for your tests. &lt;/p&gt;

&lt;p&gt;Ignoring the assertions in this test - which are for demo purposes only - I prefer this test. One or two lines to setup the context and one call to the page object for the action I'm testing. This reads much more like a specification, which I think makes it a lot easier for the Test Reader to quickly see what is going on, and makes the tests a lot easier to maintain over time.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Test]
public void CanPopulateFormFromModel()
{
    var student = Builder&amp;lt;CreateStudentForm&amp;gt;
        .CreateNew()
        .Build();
    var newStudentPage = Host.NavigateTo&amp;lt;StudentController, NewStudentPage&amp;gt;(x =&amp;gt; x.Create());

    newStudentPage.AddValidStudent(student);

    Host.Browser.FindElement(By.Id("FirstMidName")).GetAttribute("value").Should().Be(student.FirstMidName);
    Host.Browser.FindElement(By.Id("LastName")).GetAttribute("value").Should().Be(student.LastName);
    Host.Browser.FindElement(By.Id("EnrollmentDate")).GetAttribute("value").Should().Be(student.EnrollmentDate.ToString());
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We have a &lt;a href="https://github.com/TestStack/TestStack.Seleno/blob/master/src/TestStack.Seleno/PageObjects/Actions/PageWriter.cs"&gt;PageWriter&lt;/a&gt; class in Seleno that inputs a whole model like this and handles the different data types and other complexities. Here is a cut down version that works for the 3 text boxes in this example.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class Page&amp;lt;TModel&amp;gt; : Page
{
    ...
    public Page&amp;lt;TModel&amp;gt; InputModel(TModel model)
    {
        var type = model.GetType();
        foreach (var property in type.GetProperties())
        {
            var element = Host.Browser.FindElement(By.Name(property.Name));
            element.Clear();
            element.SendKeys(property.GetValue(model).ToString());
        }
        return this;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And the additional method on the page object.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class NewStudentPage : Page&amp;lt;CreateStudentForm&amp;gt;
{
    ...
    public StudentDetailsPage AddValidStudent(CreateStudentForm student)
    {
        InputModel(student);
        return new StudentDetailsPage();
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Display Templates do not generate IDs for controls&lt;/h2&gt;

&lt;p&gt;By default MVC only adds ID and name properties to form controls (via the &lt;strong&gt;Editor Templates&lt;/strong&gt;) with the expression-based HTML helpers. It does not do the same with the display expressions (such as &lt;code&gt;Html.DisplayFor()&lt;/code&gt;) that use the &lt;strong&gt;Display Templates&lt;/strong&gt;). &lt;/p&gt;

&lt;p&gt;For example, this code from the Student Details view (Views\Student\Details.cshtml):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;dt&amp;gt;
    @Html.DisplayNameFor(model =&amp;gt; model.LastName)
&amp;lt;/dt&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;produces the following HTML with the standard Display Templates:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;dd&amp;gt;
    Alexander
&amp;lt;/dd&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Fortunately, you can override both the Editor and Display templates if you add them to your web project. You can read all about ASP.Net MVC's templating system in &lt;a href="http://bradwilson.typepad.com/blog/2009/10/aspnet-mvc-2-templates-part-1-introduction.html"&gt;this series of posts&lt;/a&gt; from Brad Wilson. Suffice to say, for the purposes of this discussion, you can override the display templates by adding a DisplayTemplates folder to your &lt;code&gt;Views\Shared&lt;/code&gt; folder in your web project. You can copy the DisplayTemplates folder from your Visual Studio installation, or you can install the MvcDisplayTemplates package, provided by &lt;a href="https://twitter.com/matthoneycutt"&gt;Matt Honeycutt&lt;/a&gt; on NuGet:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Install-Package MvcDisplayTemplates
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This overrides the &lt;code&gt;_Layout.cshtml&lt;/code&gt; file in the &lt;code&gt;Views\Shared\DisplayTemplates&lt;/code&gt; folder to wrap each model property in the view with a span that uses the &lt;code&gt;Html.IdForModel&lt;/code&gt; Html Helper from System.Web.Mvc to generate an ID for the property control. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@model dynamic
@if (HttpContext.Current.IsDebuggingEnabled)
{ 
    &amp;lt;span id="@Html.IdForModel()"&amp;gt;@RenderBody()&amp;lt;/span&amp;gt;
}
else
{
    @RenderBody()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now the &lt;code&gt;Html.DisplayNameFor&lt;/code&gt; expression above generates this HTML, with the value wrapped in a span with an ID. Now that all of our view model properties are named with a well-known, predictable, naming convention, we can set about automating the reading of these properties into a view model in our tests in an automated fashion.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;dd&amp;gt;
    &amp;lt;span id="LastName"&amp;gt;Alexander&amp;lt;/span&amp;gt;
&amp;lt;/dd&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Read View Model Property from Web Page&lt;/h2&gt;

&lt;p&gt;We can extend the strongly typed base page with a method to read the value from a view page, again utilising the &lt;code&gt;ExpressionHelper&lt;/code&gt; class from System.Web.Mvc. The &lt;a href="http://msdn.microsoft.com/en-us/library/system.web.mvc.tagbuilder.createsanitizedid%28v=vs.111%29.aspx"&gt;TagBuilder.CreateSanitizedId&lt;/a&gt; method is another System.Web.Mvc helper that ensures only valid HTML characters are used .&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public string DisplayFor&amp;lt;TField&amp;gt;(Expression&amp;lt;Func&amp;lt;TModel, TField&amp;gt;&amp;gt; field)
{
    string name = ExpressionHelper.GetExpressionText(field);
    string id = TagBuilder.CreateSanitizedId(name);

    var span = Host.Browser.FindElement(By.Id(id));

    return span.Text;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which can be used in tests in the following way:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Test]
public void CanReadFormFieldFromModelProperty()
{
    var studentDetailsPage = Host.NavigateTo&amp;lt;StudentController, StudentDetailsPage&amp;gt;(x =&amp;gt; x.Details(1));

    studentDetailsPage
        .DisplayFor(x =&amp;gt; x.LastName)
        .Should().Be("Alexander");
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Read Whole View Model From Web Page&lt;/h2&gt;

&lt;p&gt;As with writing view model data to the page, we can extend this concept to read the whole view model from the page. Again, Seleno has a more fully featured &lt;a href="https://github.com/TestStack/TestStack.Seleno/blob/master/src/TestStack.Seleno/PageObjects/Actions/PageReader.cs"&gt;PageReader&lt;/a&gt; class, but here is a cut down version to illustrate the principle:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public TModel ReadModel()
{
    var type = typeof(TModel);
    var instance = new TModel();

    foreach (var property in type.GetProperties())
    {
        string name = ExpressionHelper.GetExpressionText(property.Name);
        string id = TagBuilder.CreateSanitizedId(name);

        var span = Host.Browser.FindElement(By.Id(id));
        property.SetValue(instance, span.Text, null);
    }

    return instance;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which you could use in tests similar to this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Test]
public void CanReadModelFromPage()
{
    var studentDetailsPage = Host.NavigateTo&amp;lt;StudentController, StudentDetailsPage&amp;gt;(x =&amp;gt; x.Details(1));

    StudentDetailsViewModel model = studentDetailsPage.ReadModel();

    model.FirstMidName.Should().Be("Carson");
    model.LastName.Should().Be("Alexander");
}
&lt;/code&gt;&lt;/pre&gt;
</content></entry></feed>