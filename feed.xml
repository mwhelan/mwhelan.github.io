<feed xmlns="http://www.w3.org/2005/Atom"><title type="text">michael whelan</title><subtitle type="text">michael whelan</subtitle><id>http://www.michael-whelan.net/</id><updated>2016-07-31T15:33:50+01:00</updated><author><name>Michael Whelan</name><uri>http://www.michael-whelan.net</uri><email>mjmwdev@gmail.com</email></author><generator>Sandra.Snow Atom Generator</generator><link rel="alternate" href="http://www.michael-whelan.net/feed.xml" /><link rel="self" type="text/html" title="michael whelan" href="http://www.michael-whelan.net/feed.xml" /><entry><id>http://www.michael-whelan.net/continuous-delivery-github-cake-gittools-appveyor/</id><title type="text">Continuous Delivery for .Net Core with GitHub, Cake, GitTools, and AppVeyor</title><summary type="html">&lt;p&gt;This is an end-to-end tutorial for setting up &lt;a href="http://www.martinfowler.com/articles/continuousIntegration.html"&gt;continuous integration&lt;/a&gt; (CI) and &lt;a href="http://www.martinfowler.com/articles/continuousIntegration.html"&gt;continuous delivery&lt;/a&gt; (CD) for a .Net Core project hosted on GitHub using Cake, GitTools, and AppVeyor. Credit for this entire process goes to &lt;a href="https://twitter.com/JakeGinnivan"&gt;Jake Ginnivan&lt;/a&gt;, who set this up for TestStack's &lt;a href="https://github.com/TestStack/TestStack.BDDfy"&gt;BDDfy&lt;/a&gt; open source project, and is actively involved in a number of the GitTools projects referenced here. I have replicated that process for another open source project and documented it here.&lt;/p&gt;

</summary><published>2016-07-31T07:00:00Z</published><updated>2016-07-31T07:00:00Z</updated><link rel="alternate" href="http://www.michael-whelan.net/continuous-delivery-github-cake-gittools-appveyor/" /><content type="html">&lt;p&gt;This is an end-to-end tutorial for setting up &lt;a href="http://www.martinfowler.com/articles/continuousIntegration.html"&gt;continuous integration&lt;/a&gt; (CI) and &lt;a href="http://www.martinfowler.com/articles/continuousIntegration.html"&gt;continuous delivery&lt;/a&gt; (CD) for a .Net Core project hosted on GitHub using Cake, GitTools, and AppVeyor. Credit for this entire process goes to &lt;a href="https://twitter.com/JakeGinnivan"&gt;Jake Ginnivan&lt;/a&gt;, who set this up for TestStack's &lt;a href="https://github.com/TestStack/TestStack.BDDfy"&gt;BDDfy&lt;/a&gt; open source project, and is actively involved in a number of the GitTools projects referenced here. I have replicated that process for another open source project and documented it here.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;Continuous delivery can be quite a daunting prospect these days and it would be easy to be overwhelmed by the number of different things the process I describe here does. But, rest assured, I am far from being an expert in this area, so if I can do it you can too. The good news is that the hard work and ingenuity has been done by the folks behind Cake, GitTools, AppVeyor and the other open source tools. They have created all the jigsaw pieces and all that is left for you and me to do is to compose the modules together to suit our particular situation.&lt;/p&gt;

&lt;h2&gt;Overview&lt;/h2&gt;

&lt;p&gt;The .Net Core project for this tutorial is &lt;a href="https://github.com/mwhelan/Specify"&gt;Specify&lt;/a&gt;: Its technology stack is:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;C#&lt;/strong&gt;: The programming language used for Specify.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NUnit&lt;/strong&gt;: The testing framework I am using in Specify (though with .Net Core you could have a mix of test frameworks as Cake just delegates to the dotnet-test runner to run tests).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Git and GitHub&lt;/strong&gt;: The Specify repository is git and the project is hosted on GitHub.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AppVeyor&lt;/strong&gt;: An online continuous integration server for .Net projects.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NuGet&lt;/strong&gt;: the package manager for .Net which is where Specify is deployed to.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cake&lt;/strong&gt;: A cross platform build automation system with a C# DSL.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GitTools&lt;/strong&gt;: A GitHub open source organisation which provide a bunch of assorted git related tools which help with debugging, versioning, releasing etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That said, many of the topics in this post are more or less applicable to other technologies and providers, mainly due to the agnosticism of the Cake build tool.&lt;/p&gt;

&lt;p&gt;The end-to-end process is comprised of these 3 steps, as depicted in the diagram below:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/cake-continuous-delivery.png" alt="Cake continuous delivery" /&gt;&lt;/p&gt;

&lt;h3&gt;Step 1: Commit code to GitHub&lt;/h3&gt;

&lt;p&gt;When you commit your code to GitHub, a webhook for AppVeyor is triggered to kick off the continuous integration build. For every project AppVeyor will configure webhooks for its repository to automatically start a build when you push the changes. You can read more about configuring AppVeyor to work with GitHub (and other providers) &lt;a href="https://www.appveyor.com/docs"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;Step 2: Continuous Integration&lt;/h3&gt;

&lt;p&gt;AppVeyor runs the Cake continuous integration build process by calling the &lt;code&gt;build.ps1&lt;/code&gt; PowerShell script. This calls the &lt;code&gt;build.cake&lt;/code&gt; script, which does all the work, and runs the following tasks (the continuous integration tasks are blue in the diagram):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Build&lt;/strong&gt;: 
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Clean&lt;/strong&gt;: Cleans the previous build (deleting and re-creating the folder used for build output). &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Semantic Version&lt;/strong&gt;: Uses GitVersion to calculate the semantic version and update the AssemblyInfo.cs files with that version. &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Package restore&lt;/strong&gt;: Performs a NuGet package restore. &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Build&lt;/strong&gt;: Compiles the source code with msbuild.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Test&lt;/strong&gt;: Runs tests for each of the test projects and for each target in those projects.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Package&lt;/strong&gt;: generates NuGet packages
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;GitHub source stepping&lt;/strong&gt;: Uses GitLink to allow consumers of this project to step through the exact version of code on GitHub that was used to create the package (an alternative approach to symbol servers).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Release notes&lt;/strong&gt;: Uses GitReleaseNotes to automatically generate release notes from the GitHub issue tracker based on closed issues since the last release.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Package for NuGet&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Step 3: Continuous Delivery&lt;/h3&gt;

&lt;p&gt;AppVeyor runs the Cake deployment process by calling the &lt;code&gt;deploy.ps1&lt;/code&gt; PowerShell script. This calls the &lt;code&gt;deploy.cake&lt;/code&gt; script, which does all the work, and runs the publish tasks (green on the diagram above):
Manually run the deploy process, etc. &lt;/p&gt;

&lt;h3&gt;Cake&lt;/h3&gt;

&lt;p&gt;&lt;a href="http://cakebuild.net/"&gt;Cake&lt;/a&gt; (C# Make) is a cross platform build automation system with a C# DSL to do things like compiling code, copy files/folders, running unit tests, compress files and build NuGet packages. It is built on top of the Roslyn and Mono compiler which enables you to write your build scripts in C#. One of its main philosophies is that Cake should behave the same way regardless of operating system (Windows, Linux, or OS X) or environment (AppVeyor, VSTS, TeamCity, Jenkins, etc.).&lt;/p&gt;

&lt;p&gt;You can read how to get started with Cake &lt;a href="http://cakebuild.net/docs/tutorials/getting-started"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Tasks represent a unit of work in Cake, and you use them to perform specific work in a specific order. You can read more about tasks &lt;a href="http://cakebuild.net/docs/fundamentals/tasks"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Cake supports something called script aliases. Script aliases are convenience methods that are easily accessible directly from a Cake script. Every single DSL method in Cake is implemented like an alias method. You can read more about Cake aliases &lt;a href="http://cakebuild.net/docs/fundamentals/aliases"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;GitTools&lt;/h3&gt;

&lt;p&gt;&lt;a href="https://github.com/GitTools"&gt;GitTools&lt;/a&gt; is a GitHub open source organisation which provide a bunch of assorted git related tools which help with debugging, versioning, releasing etc.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;GitVersion&lt;/strong&gt;: Provides easy, automated, &lt;a href="http://semver.org/"&gt;semantic versioning&lt;/a&gt; for projects using git, by looking at your git history and working out the semantic version of the commit being built.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GitLink&lt;/strong&gt;: Allows users to step through your source code hosted on GitHub, making symbol servers obsolete.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GitReleaseNotes&lt;/strong&gt;: Utility which makes it really easy to generate release notes for your git project. Works with GitHub, Jira and YouTrack.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Continuous Integration&lt;/h2&gt;

&lt;h3&gt;Build task&lt;/h3&gt;

&lt;p&gt;This illustrates a basic Cake task. You can see that it is familiar C# syntax. Each task defines a name - "Build" in this case - and is followed by a &lt;code&gt;.Does&lt;/code&gt; method which takes a lambda for the work the task will perform.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;IsDependentOn&lt;/code&gt; method is used to setup a dependency on another task. That means that task must run before this task. If there are multiple dependencies then each will run in order before this task. So, in this example, they will run in the following order: &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Clean =&amp;gt; Version =&amp;gt; Restore =&amp;gt; Build.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;build&lt;/code&gt; task uses the Cake MSBuild task to compile the Specify solution.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Task("Build")
    .IsDependentOn("Clean")
    .IsDependentOn("Version")
    .IsDependentOn("Restore")
    .Does(() =&amp;gt; {
        MSBuild("./src/Specify.sln");
    });
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In order to use the commands for this alias, MSBuild will already have to be installed on the machine the Cake Script is being executed on.&lt;/p&gt;

&lt;h3&gt;Clean task&lt;/h3&gt;

&lt;p&gt;The first task you normally want to do with a build script is to delete the working directory, which various tasks in the build process use for preparing files and producing output. Cake provides a number of aliases for working with directories. This script uses the &lt;code&gt;DirectoryExists&lt;/code&gt;, &lt;code&gt;DeleteDirectory&lt;/code&gt;, and &lt;code&gt;CreateDirectory&lt;/code&gt; methods.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Task("Clean")
    .Does(() =&amp;gt; {
        if (DirectoryExists(outputDir))
        {
            DeleteDirectory(outputDir, recursive:true);
        }
        CreateDirectory(outputDir);
    });
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Version task&lt;/h3&gt;

&lt;p&gt;The version task uses the GitVersion tool to calculate the &lt;a href="http://semver.org/"&gt;semantic version&lt;/a&gt; of the project and updates the project's project.json and AssemblyInfo.cs files with this version number. You can read more about GitVersion on the project's &lt;a href="http://gitversion.readthedocs.io/en/latest/"&gt;readthedocs site&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In order to use the GitVersion tool, you have to download its package as part of executing the build script. To do that with Cake, you have to provide this directive at the top of the build script.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#tool "nuget:?package=GitVersion.CommandLine"
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And then use the GitVersion alias and the GitVersionSettings class in the version task.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Task("Version")
    .Does(() =&amp;gt; {
        GitVersion(new GitVersionSettings{
            UpdateAssemblyInfo = true,
            OutputType = GitVersionOutput.BuildServer
        });
        versionInfo = GitVersion(new GitVersionSettings{ OutputType = GitVersionOutput.Json });
        // Update project.json
        var updatedProjectJson = System.IO.File.ReadAllText(specifyProjectJson)
            .Replace("1.0.0-*", versionInfo.NuGetVersion);

        System.IO.File.WriteAllText(specifyProjectJson, updatedProjectJson);
    });
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Restore task&lt;/h3&gt;

&lt;p&gt;Cake provides built-in support for .Net Core. The DotNetCoreRestore alias will restore all NuGet packages for .Net Core solutions. You just have to pass in the folder where the solution is located ("src" in this example).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Task("Restore")
    .Does(() =&amp;gt; {
        DotNetCoreRestore("src");
    });
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In order to use the commands for this alias, the &lt;a href="https://www.microsoft.com/net/core#windows"&gt;.Net Core CLI tools&lt;/a&gt; will need to be installed on the machine where the Cake script is being executed.&lt;/p&gt;

&lt;h3&gt;Test task&lt;/h3&gt;

&lt;p&gt;DotNetCoreTest is another DotNetCore alias. It will use the .Net CLI test runner that is configured for each test project to run the tests for that project. It will run tests for each target defined in the test project's project.json file. You just have to pass in the location of the test project.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DotNetCoreTest("./src/tests/Specify.Tests");
DotNetCoreTest("./src/tests/Specify.IntegrationTests");
DotNetCoreTest("./src/Samples/Examples/Specify.Examples.UnitSpecs");
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In order to use the commands for this alias, the &lt;a href="https://www.microsoft.com/net/core#windows"&gt;.Net Core CLI tools&lt;/a&gt; will need to be installed on the machine where the Cake script is being executed.&lt;/p&gt;

&lt;h3&gt;Package task&lt;/h3&gt;

&lt;p&gt;The package task performs performs several operations to create  runs once for each &lt;/p&gt;

&lt;h3&gt;GitHub source stepping task&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;UPDATE&lt;/strong&gt;: Unfortunately, it turns out that GitLink does not currently support xproj or project.json and .Net Core. I will leave this step in as it is still a correct description of how to use Cake and GitLink with pre-.Net Core projects and perhaps suppor will be added eventually. As an alternative, I will demonstrate packaging pdb files as a NuGet package for a symbol server in a later step.&lt;/p&gt;

&lt;p&gt;In order to use the GitLink tool, you have to download its package as part of executing the build script. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#tool "nuget:?package=gitlink"
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And then use the GitLink alias and the GitVersionSettings class in the package task. This example shows how to include command-line arguments that tell GitLink which projects in the solution to target.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;GitLink("./", new GitLinkSettings { ArgumentCustomization = args =&amp;gt; args.Append("-include Specify,Specify.Autofac") });
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Alternatively, you can just call it without any settings and accept the defaults:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;GitLink("./");
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Release notes task&lt;/h3&gt;

&lt;p&gt;In order to use the GitReleaseNotes tool, you have to download its package as part of executing the build script. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#tool "nuget:?package=GitReleaseNotes"
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Although there is a GitReleaseNotes tool for Cake, this example shows how to use the StartProcess alias to run the GitReleaseNotes executable that Cake has downloaded to the tools directory.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private void GenerateReleaseNotes()
{
    var releaseNotesExitCode = StartProcess(
        @"tools\GitReleaseNotes\tools\gitreleasenotes.exe", 
        new ProcessSettings { Arguments = ". /o artifacts/releasenotes.md" });
    if (string.IsNullOrEmpty(System.IO.File.ReadAllText("./artifacts/releasenotes.md")))
        System.IO.File.WriteAllText("./artifacts/releasenotes.md", "No issues closed since last release");

    if (releaseNotesExitCode != 0) throw new Exception("Failed to generate release notes");
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Package for NuGet task&lt;/h3&gt;

&lt;p&gt;The package task generates the .nupkg files for each project that needs to be deployed to NuGet using Cake's DotNetCorePack alias. This is another DotNetCore alias, and also requires the .Net Core CLI tools be installed on the machine where the Cake script is being executed. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private void PackageProject(string projectName, string projectJsonPath)
{
    var settings = new DotNetCorePackSettings
        {
            OutputDirectory = outputDir,
            NoBuild = true
        };

    DotNetCorePack(projectJsonPath, settings);

    System.IO.File.WriteAllLines(outputDir + "artifacts", new[]{
        "nuget:" + projectName + "." + versionInfo.NuGetVersion + ".nupkg",
        "nugetSymbols:" + projectName + "." + versionInfo.NuGetVersion + ".symbols.nupkg",
        "releaseNotes:releasenotes.md"
    });
} 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that this also generates the symbols package for uploading the .pdb files to a symbol server (as an alternative to GitHub source stepping).&lt;/p&gt;

&lt;p&gt;If the script is running on AppVeyor then it copies all the generated output to the Artifacts folder on AppVeyor that is associated with this build.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/cake-appveyor-artifacts.png" alt="AppVeyor artifacts" /&gt;&lt;/p&gt;

&lt;h3&gt;Final Cake Continuous Integration build script&lt;/h3&gt;

&lt;p&gt;Having seen all the constituent parts it's probably useful to see the whole script:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#tool "nuget:?package=GitReleaseNotes"
#tool "nuget:?package=GitVersion.CommandLine"
#tool "nuget:?package=gitlink"

var target = Argument("target", "Default");
var outputDir = "./artifacts/";
var solutionPath = "./src/Specify.sln";
var specifyProjectJson = "./src/app/Specify/project.json";
var specifyAutofacProjectJson = "./src/app/Specify.Autofac/project.json";

Task("Clean")
    .Does(() =&amp;gt; {
        if (DirectoryExists(outputDir))
        {
            DeleteDirectory(outputDir, recursive:true);
        }
        CreateDirectory(outputDir);
    });

Task("Restore")
    .Does(() =&amp;gt; {
        DotNetCoreRestore("src");
    });

GitVersion versionInfo = null;
Task("Version")
    .Does(() =&amp;gt; {
        GitVersion(new GitVersionSettings{
            UpdateAssemblyInfo = true,
            OutputType = GitVersionOutput.BuildServer
        });
        versionInfo = GitVersion(new GitVersionSettings{ OutputType = GitVersionOutput.Json });
        // Update project.json
        var updatedProjectJson = System.IO.File.ReadAllText(specifyProjectJson)
            .Replace("1.0.0-*", versionInfo.NuGetVersion);

        System.IO.File.WriteAllText(specifyProjectJson, updatedProjectJson);
    });

Task("Build")
    .IsDependentOn("Clean")
    .IsDependentOn("Version")
    .IsDependentOn("Restore")
    .Does(() =&amp;gt; {
        MSBuild(solutionPath);
    });

Task("Test")
    .IsDependentOn("Build")
    .Does(() =&amp;gt; {
        DotNetCoreTest("./src/tests/Specify.Tests");
        DotNetCoreTest("./src/tests/Specify.IntegrationTests");
        DotNetCoreTest("./src/Samples/Examples/Specify.Examples.UnitSpecs");
    });

Task("Package")
    .IsDependentOn("Test")
    .Does(() =&amp;gt; {
        //GitLink("./", new GitLinkSettings { ArgumentCustomization = args =&amp;gt; args.Append("-include Specify,Specify.Autofac") });

        GenerateReleaseNotes();

        PackageProject("Specify", specifyProjectJson);
        PackageProject("Specify.Autofac", specifyAutofacProjectJson);

        if (AppVeyor.IsRunningOnAppVeyor)
        {
            foreach (var file in GetFiles(outputDir + "**/*"))
                AppVeyor.UploadArtifact(file.FullPath);
        }
    });

private void PackageProject(string projectName, string projectJsonPath)
{
    var settings = new DotNetCorePackSettings
        {
            OutputDirectory = outputDir,
            NoBuild = true
        };

    DotNetCorePack(projectJsonPath, settings);

    System.IO.File.WriteAllLines(outputDir + "artifacts", new[]{
        "nuget:" + projectName + "." + versionInfo.NuGetVersion + ".nupkg",
        "nugetSymbols:" + projectName + "." + versionInfo.NuGetVersion + ".symbols.nupkg",
        "releaseNotes:releasenotes.md"
    });
}    

private void GenerateReleaseNotes()
{
        var releaseNotesExitCode = StartProcess(
        @"tools\GitReleaseNotes\tools\gitreleasenotes.exe", 
        new ProcessSettings { Arguments = ". /o artifacts/releasenotes.md" });
    if (string.IsNullOrEmpty(System.IO.File.ReadAllText("./artifacts/releasenotes.md")))
        System.IO.File.WriteAllText("./artifacts/releasenotes.md", "No issues closed since last release");

    if (releaseNotesExitCode != 0) throw new Exception("Failed to generate release notes");
}

Task("Default")
    .IsDependentOn("Package");

RunTarget(target);
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;AppVeyor badge&lt;/h3&gt;

&lt;p&gt;A project status badge is a dynamically generated image displaying the status of the last AppVeyor build. You can put a status badge on the home page of your GitHub project (in the readme.md file). &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[![Build status](https://ci.appveyor.com/api/projects/status/vj6ec2yubg8ii9sn?svg=true)](https://ci.appveyor.com/project/mwhelan/specify)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/cake-appveyor-badge.svg" alt="AppVeyor artifacts" /&gt;&lt;/p&gt;

&lt;p&gt;You can read more about AppVeyor status badges &lt;a href="https://www.appveyor.com/docs/status-badges"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2&gt;Continuous Delivery&lt;/h2&gt;

&lt;p&gt;I have not had time to replicate the BDDfy deployment to NuGet process, so I will just outline the steps we take to deploy BDDfy. &lt;/p&gt;

&lt;p&gt;The process has two steps, each of which has its own project in AppVeyor. The first step is to create a GitHub release. That is done by the CI build, which is configured to not build tags. The second step is to deploy to NuGet. This is done by a dedicated AppVeyor project for deployment which is configured to only build tags. Tags are created when you publish the GitHub Release.&lt;/p&gt;

&lt;h3&gt;Step 1: Publish a GitHub Release&lt;/h3&gt;

&lt;p&gt;The deployment process starts by selecting &lt;code&gt;Deploy&lt;/code&gt; from the continuous integration build to create a new deployment. &lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/cake-appveyor-deploy1.png" alt="AppVeyor deploy" /&gt;&lt;/p&gt;

&lt;p&gt;Select &lt;code&gt;Create GitHub Release - GitHub Releases&lt;/code&gt; option for the Environment and then click &lt;code&gt;Deploy&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/cake-appveyor-deploy2.png" alt="AppVeyor deploy" /&gt;&lt;/p&gt;

&lt;p&gt;This will run and generate a GitHub Release.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/cake-appveyor-deploy3.png" alt="AppVeyor deploy" /&gt;&lt;/p&gt;

&lt;p&gt;Now, if you go over to GitHub Releases for your project you should see a new Draft Release.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/cake-appveyor-deploy4.png" alt="AppVeyor deploy" /&gt;&lt;/p&gt;

&lt;p&gt;At this stage, this requires some manual editing of the title and tag and perhaps making some changes to the release notes. &lt;/p&gt;

&lt;p&gt;Once everything is OK, publish the GitHub Release. This will create a tag, which will kick off the AppVeyor deployment project (which is configured to only build tags).&lt;/p&gt;

&lt;h3&gt;Step 2: Deploy to NuGet&lt;/h3&gt;

&lt;p&gt;The BDDfy deployment process is defined in the &lt;a href="https://github.com/TestStack/TestStack.BDDfy/blob/master/deploy.cake"&gt;deploy.cake file&lt;/a&gt;. It downloads GitHub Release artifacts and then deploys to NuGet. &lt;/p&gt;

&lt;h2&gt;Summary&lt;/h2&gt;

&lt;p&gt;So, that is an end-to-end process for setting up continuous integration and continuous delivery for a .Net Core project hosted on GitHub using Cake, GitTools, and AppVeyor. It is one of my longer posts, and there's a whole lot going on, but hopefully it provides some useful insight into some of the great tools that talented people have made available for the community and how you might be able to use them in your own processes.&lt;/p&gt;
</content></entry><entry><id>http://www.michael-whelan.net/testing-dotnet-core-with-testdriven-net/</id><title type="text">Testing .Net Core with TestDriven.Net</title><summary type="html">&lt;p&gt;Third party tools vendors are finding it particularly difficult to provide .Net Core support while the tooling is in preview and still subject to a lot of change, but TestDriven.Net is leading the way with a slick Visual Studio testing experience for .Net Core (and earlier versions of .Net).  You simply right click on the solution, project, folder, file, or test, and it will run all of the tests in that scope. TestDriven.Net is actually one of the oldest .Net/Visual Studio test runners and is undergoing something of a reboot with support for .Net Core and the next version of Visual Studio, "15."&lt;/p&gt;

</summary><published>2016-07-22T07:00:00Z</published><updated>2016-07-22T07:00:00Z</updated><link rel="alternate" href="http://www.michael-whelan.net/testing-dotnet-core-with-testdriven-net/" /><content type="html">&lt;p&gt;Third party tools vendors are finding it particularly difficult to provide .Net Core support while the tooling is in preview and still subject to a lot of change, but TestDriven.Net is leading the way with a slick Visual Studio testing experience for .Net Core (and earlier versions of .Net).  You simply right click on the solution, project, folder, file, or test, and it will run all of the tests in that scope. TestDriven.Net is actually one of the oldest .Net/Visual Studio test runners and is undergoing something of a reboot with support for .Net Core and the next version of Visual Studio, "15."&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;h2&gt;TestDriven.Net v4 Alpha&lt;/h2&gt;

&lt;p&gt;&lt;a href="https://twitter.com/jcansdale"&gt;Jamie Cansdale&lt;/a&gt;, the maintainer of the venerable TestDriven.Net, has been hard at work releasing a number of alpha versions through the &lt;a href="http://testdriven.net/download.aspx"&gt;testdriven.net website&lt;/a&gt;. The releases consist of .zip files that contain a setup.exe executable for installing TestDriven.Net as a Visual Studio add-in. &lt;/p&gt;

&lt;p&gt;You can read the release notes &lt;a href="http://testdriven.net/downloads/releasenotes.html"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2&gt;Running Tests&lt;/h2&gt;

&lt;p&gt;TestDriven.net is extremely flexible and can be run in a number of ways.&lt;/p&gt;

&lt;h3&gt;Running Tests from Solution Explorer&lt;/h3&gt;

&lt;p&gt;After installing TestDriven.Net, and re-starting Visual Studio, the 'Run Test(s)' command becomes available on the Right-Click context menu in Solution Explorer, and offers a straightforward way to build and run tests. You can right click on the solution, a project (or multiple projects), or a file (or multiple files) and it will run all of the tests in that scope. You have a number of useful testing options, such as testing with the debugger or code coverage.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/test-dotnet-core-tdnet-run.png" alt="VS test runner" /&gt;&lt;/p&gt;

&lt;p&gt;This is intended to be the default method of test execution in most contexts. TestDriven.Net automatically detects the test framework being used and executes tests using the correct test runner. The tests are launched by a test execution engine running as an external process. This test process is kept alive in order to improve execution times on subsequent runs. Once a test process has been cached, a rocket icon will appear in the notify box.&lt;/p&gt;

&lt;h3&gt;Running Tests from the Code Editor Window&lt;/h3&gt;

&lt;p&gt;If the code editor window is selected, the test(s) to execute will be determined by the position of the caret:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;individual tests are executed by right-clicking anywhere inside a test method and selecting 'Run Test(s)'&lt;/li&gt;
&lt;li&gt;all tests in a test fixture are executed by right-clicking inside a class (but outside of any method) and selecting 'Run Test(s)'&lt;/li&gt;
&lt;li&gt;all tests in a namespace are executed by right-clicking inside a namespace and selecting 'Run Test(s)'.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Test Results&lt;/h3&gt;

&lt;p&gt;Once your run the tests, TestDriven.Net will show the results in the "Test" output window.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/test-dotnet-core-tdnet.png" alt="VS test runner" /&gt;&lt;/p&gt;

&lt;h2&gt;Tips and Tricks&lt;/h2&gt;

&lt;p&gt;It is important to remember that TestDriven.Net v4 is an alpha, and not everything works quite as well as it will in the final release. This is sometimes down to the vagaries of how Visual Studio works, not to mention the issues that all tools vendors are facing with the moving target of the Visual Studio .Net Core preview tooling. So, hopefully some of these things will improve with time.&lt;/p&gt;

&lt;h3&gt;The order of frameworks matter when multi-targeting&lt;/h3&gt;

&lt;p&gt;If you are targeting multiple frameworks in your test project and you put the .Net 4x project first, TestDriven.Net won't run your tests. It is important to put the .Net Core framework first in your project.json. For example, here netcoreapp1.0 is listed before net46.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"frameworks": {
    "netcoreapp1.0": {
        "dependencies": {
            "Microsoft.NETCore.App": {
                "type": "platform",
                "version": "1.0.0"
            },
            "System.Linq": "4.1.0"
        },
        "imports": [
            "dnxcore50",
            "portable-net45+win8"
        ]
    },
    "net46": {
        "dependencies": {
        },
        "buildOptions": {
            "define": [
                "Approvals",
                "Culture",
                "NSubstitute"
            ]
        }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Runtimes&lt;/h3&gt;

&lt;p&gt;I had an issue where some of my tests just weren't working. When I ran them nothing would happen - nothing was displayed in the "Test" output window and the status bar said &lt;code&gt;0 passed, 0 Failed, 0 Skipped&lt;/code&gt;. It turned out the problem was having a Runtimes node in my test project's project.json.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"runtimes": {
    "win10-x64": {}
},
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This made Visual Studio incorrectly report to TestDriven.Net that my test project's DLL was in the &lt;code&gt;bin\Debug\netcoreapp1.0\win10-x64&lt;/code&gt; directory, when in fact it was in the &lt;code&gt;bin\Debug\netcoreapp1.0&lt;/code&gt; directory. Removing the runtimes node solved the problems and enabled TestDriven.Net to run the tests successfully.&lt;/p&gt;

&lt;h3&gt;Execute non-test methods&lt;/h3&gt;

&lt;p&gt;The .NET Core test runner requires that unit tests be inside a Console Application project, but TestDriven.Net can actually execute any method/property that doesn't have a test attribute as an "Ad hoc" test (even if it's inside a Class Library project). Anything returned from the method/property will be expanded on the output window. &lt;/p&gt;

&lt;p&gt;This feature can make it a really interesting utility for running your own methods. For example, if you wanted to find out more about the properties on a type:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/tdnet-normal-method.png" alt="TestDriven.Net" /&gt;&lt;/p&gt;

&lt;h2&gt;Get Involved&lt;/h2&gt;

&lt;p&gt;TestDriven.Net is still in alpha and Jamie Cansdale is actively looking at ways to make it as useful as possible. That means that you have the opportunity to shape its direction by raising issues on the &lt;a href="https://github.com/jcansdale/TestDriven.Net-Issues/issues"&gt;GitHub issues page&lt;/a&gt; or &lt;a href="https://twitter.com/jcansdale"&gt;tweeting Jamie&lt;/a&gt; with feature requests. Give it a try.&lt;/p&gt;

&lt;p&gt;For example, Jamie mentioned to me that he is thinking about how to allow people to swap between the different frameworks. At the moment he is thinking of adding separate &lt;code&gt;Test With &amp;gt; .NET Core&lt;/code&gt; and &lt;code&gt;Test With &amp;gt; .NET 4.x&lt;/code&gt; options, but he would appreciate feedback and suggestions about how this might work best.&lt;/p&gt;

&lt;h2&gt;Summary&lt;/h2&gt;

&lt;p&gt;There are not a lot of .Net Core test runners available at the moment. TestDriven.Net may only be in alpha, but it is already very stable for day-to-day testing of your .Net Core projects and is a slick and flexible way to run your tests in Visual Studio. I recommend &lt;a href="http://testdriven.net/download.aspx"&gt;checking it out&lt;/a&gt;.&lt;/p&gt;
</content></entry><entry><id>http://www.michael-whelan.net/using-humanizer-with-asp-dotnet-core/</id><title type="text">A Humanizer Display Metadata Provider for ASP .Net Core</title><summary type="html">&lt;p&gt;I have always been a big fan of using a Humanizer model metadata provider in my ASP.Net MVC applications. This means that Humanizer will automatically put spaces into labels for multi-word view model property names rather than the developer having to manually add a lot of data annotation Display attributes to those view model property names. The APIs have changed a little for ASP.Net Core, but the approach is basically the same. &lt;/p&gt;

</summary><published>2016-07-18T07:00:00Z</published><updated>2016-07-18T07:00:00Z</updated><link rel="alternate" href="http://www.michael-whelan.net/using-humanizer-with-asp-dotnet-core/" /><content type="html">&lt;p&gt;I have always been a big fan of using a Humanizer model metadata provider in my ASP.Net MVC applications. This means that Humanizer will automatically put spaces into labels for multi-word view model property names rather than the developer having to manually add a lot of data annotation Display attributes to those view model property names. The APIs have changed a little for ASP.Net Core, but the approach is basically the same. &lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;h2&gt;What it does&lt;/h2&gt;

&lt;p&gt;You can read about the approach for classic MVC in &lt;a href="http://www.mehdi-khalili.com/introducing-humanizer/#what-else"&gt;Mehdi's introductory Humanizer post&lt;/a&gt;. Basically, instead of the &lt;code&gt;ReleaseDate&lt;/code&gt; label:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/humanizer-original.png" alt="VS test runner" /&gt; &lt;/p&gt;

&lt;p&gt;you get the preferable &lt;code&gt;Release Date&lt;/code&gt;, with a space between the words.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/humanizer-after.png" alt="VS test runner" /&gt; &lt;/p&gt;

&lt;h2&gt;How it works&lt;/h2&gt;

&lt;p&gt;Rather than inherit from the DataAnnotationsModelMetadataProvider as you did in classic MVC, with ASP.Net Core you need to implement the &lt;code&gt;IDisplayMetadataProvider&lt;/code&gt; interface from the &lt;code&gt;Microsoft.AspNetCore.Mvc.ModelBinding.Metadata&lt;/code&gt; namespace. The implementation is otherwise very similar:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System.Collections.Generic;
using System.ComponentModel;
using System.ComponentModel.DataAnnotations;
using System.Linq;
using Humanizer;
using Microsoft.AspNetCore.Mvc.ModelBinding.Metadata;

public class HumanizerMetadataProvider : IDisplayMetadataProvider
{
    public void CreateDisplayMetadata(DisplayMetadataProviderContext context)
    {
        var propertyAttributes = context.Attributes;
        var modelMetadata = context.DisplayMetadata;
        var propertyName = context.Key.Name;

        if (IsTransformRequired(propertyName, modelMetadata, propertyAttributes))
        {
            modelMetadata.DisplayName = () =&amp;gt; propertyName.Humanize().Transform(To.TitleCase);
        }
    }

    private static bool IsTransformRequired(string propertyName, DisplayMetadata modelMetadata, IReadOnlyList&amp;lt;object&amp;gt; propertyAttributes)
    {
        if (!string.IsNullOrEmpty(modelMetadata.SimpleDisplayProperty))
            return false;

        if (propertyAttributes.OfType&amp;lt;DisplayNameAttribute&amp;gt;().Any())
            return false;

        if (propertyAttributes.OfType&amp;lt;DisplayAttribute&amp;gt;().Any())
            return false;

        if (string.IsNullOrEmpty(propertyName))
            return false;

        return true;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To wire it up, you configure it in the ConfigureServices method of Startup.cs. You add the custom HumanizerMetadataProvider provider to the ModelMetadataDetailsProviders collection.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;services.AddMvc()
    .AddMvcOptions(m =&amp;gt; m.ModelMetadataDetailsProviders.Add(new HumanizerMetadataProvider()));
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Summary&lt;/h2&gt;

&lt;p&gt;Creating a custom model metadata provider in ASP.Net Core is quite similar to ASP.Net MVC, but the APIs have changed a little bit.&lt;/p&gt;
</content></entry><entry><id>http://www.michael-whelan.net/the-state-of-dotnet-core-testing-today/</id><title type="text">The State of .Net Core Testing Today</title><summary type="html">&lt;p&gt;.Net Core 1.0 has been officially released but the tooling is still in preview. This means that a number of open source testing libraries have been able to release at least alpha support for .Net Core, but it is not always easy to locate and you sometimes have to drill through GitHub issues, stack overflow questions, and NuGet feeds, to find it. Third party tools vendors are finding it particularly difficult to provide .Net Core support while the tooling is in preview and still subject to a lot of change, but TestDriven.Net has a number of promising alpha releases. In this post, I am going to look at the main .Net testing providers, their current support for .Net Core, and how you can get hold of them. &lt;/p&gt;

</summary><published>2016-07-17T07:00:00Z</published><updated>2016-07-17T07:00:00Z</updated><link rel="alternate" href="http://www.michael-whelan.net/the-state-of-dotnet-core-testing-today/" /><content type="html">&lt;p&gt;.Net Core 1.0 has been officially released but the tooling is still in preview. This means that a number of open source testing libraries have been able to release at least alpha support for .Net Core, but it is not always easy to locate and you sometimes have to drill through GitHub issues, stack overflow questions, and NuGet feeds, to find it. Third party tools vendors are finding it particularly difficult to provide .Net Core support while the tooling is in preview and still subject to a lot of change, but TestDriven.Net has a number of promising alpha releases. In this post, I am going to look at the main .Net testing providers, their current support for .Net Core, and how you can get hold of them. &lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;h2&gt;Test Project Configuration&lt;/h2&gt;

&lt;p&gt;The steps to create a test project are a little bit different with .Net Core. You still create it as a class library, but now you must mark it as a .Net Core Application (the &lt;code&gt;netcoreapp1.0&lt;/code&gt; framework in the project.json below).  &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"frameworks": {
    "netcoreapp1.0": {
        "dependencies": {
            "Microsoft.NETCore.App": {
                "type": "platform",
                "version": "1.0.0"
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When using the .Net CLI for testing, unit test projects are actually an application, not a class library.If you forget to make this change, the compiler will tell you that &lt;code&gt;dotnet-test-xunit&lt;/code&gt; (for example) is not compatible with your class library project. &lt;/p&gt;

&lt;p&gt;You must also add a project reference to the application project you are testing in the project.json.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"dependencies": {
    "Specify.Autofac": {
      "target": "project"
    },
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can target both net4xx and netcoreapp simply by adding both frameworks together in your project.json file. When you run dotnet test with multiple framework entries, the system will run all your framework tests, one after the other.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"frameworks": {
    "netcoreapp1.0": {
        "dependencies": {
            "Microsoft.NETCore.App": {
                "type": "platform",
                "version": "1.0.0"
            },
            "System.Linq": "4.1.0"
        },
        "imports": [
            "dnxcore50",
            "portable-net45+win8"
      ]
    },
  "net46": {
    "dependencies": {
    },
    "buildOptions": {
      "define": [
        "Approvals"
      ]
    }
  }
},
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Test Runners&lt;/h2&gt;

&lt;p&gt;Unfortunately, my favourite test runners, ReSharper and NCrunch, do not have support for .Net Core yet. That has meant that we have been stuck with either the console runners or the Visual Studio test runner. Fortunately, things are looking up, with TestDriven.Net providing a flurry of alpha packages. There are still a number of issues to work out - tests just flat out don't run on some of my projects - but it seems to be shaping up quite well and is a great option for those projects that it does work for.&lt;/p&gt;

&lt;h3&gt;TestDriven.Net v4 Alpha&lt;/h3&gt;

&lt;p&gt;&lt;a href="https://twitter.com/jcansdale"&gt;Jamie Cansdale&lt;/a&gt;, the maintainer of the venerable TestDriven.Net, has released a number of alpha versions through the &lt;a href="http://testdriven.net/default.aspx"&gt;testdriven.net website&lt;/a&gt;. The releases consist of .zip files that contain an executable for installing TestDriven.Net as a Visual Studio add-in.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/test-dotnet-core-tdnet.png" alt="VS test runner" /&gt;&lt;/p&gt;

&lt;p&gt;After installing TestDriven.Net, you can right click on the solution, a project (or multiple projects), or a file (or multiple files) and it will run all of the tests in that scope. TestDriven.Net automatically detects the test framework being used and executes tests using the correct test runner. You have a number of useful testing options, such as testing with the debugger or code coverage.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/test-dotnet-core-tdnet-run.png" alt="VS test runner" /&gt;&lt;/p&gt;

&lt;p&gt;I've written another post about how to test .Net Core with TestDriven.Net &lt;a href="http://www.michael-whelan.net/testing-dotnet-core-with-testdriven-net/"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;Console Runners&lt;/h3&gt;

&lt;p&gt;The various test frameworks implement the &lt;a href="https://docs.microsoft.com/en-us/dotnet/articles/core/tools/test-protocol"&gt;.Net Core test protocol&lt;/a&gt; to provide test runners, which allow tests to be run by the Visual Studio test runner or from the command line. &lt;/p&gt;

&lt;p&gt;To run tests from the command line, open a command prompt or PowerShell command window. In the window, navigate to the folder containing the source code of your test project. To run the .Net CLI test runner, type &lt;code&gt;dotnet test&lt;/code&gt;, as shown below:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; dotnet test
xUnit.net .NET CLI test runner (64-bit .NET Core win10-x64)
  Discovering: MyFirstDotNetCoreTests
  Discovered:  MyFirstDotNetCoreTests
  Starting:    MyFirstDotNetCoreTests
    MyFirstDotNetCoreTests.Class1.FailingTest [FAIL]
      Assert.Equal() Failure
      Expected: 5
      Actual:   4
      Stack Trace:
        C:\Samples\MyFirstDotNetCoreTests\src\MyFirstDotNetCoreTests\Class1.cs(16,0): at MyFirstDotNetCoreTests.Class1.FailingTest()
  Finished:    MyFirstDotNetCoreTests
=== TEST EXECUTION SUMMARY ===
   MyFirstDotNetCoreTests  Total: 2, Errors: 0, Failed: 1, Skipped: 0, Time: 0.167s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will kick off the tests using whichever runner is specified in the &lt;code&gt;testRunner&lt;/code&gt; node in project.json.&lt;/p&gt;

&lt;h3&gt;Run tests in Visual Studio&lt;/h3&gt;

&lt;p&gt;The same NuGet package which allows you to run tests from the console also allows you to run tests from within Visual Studio. Show the Test Explorer window by choosing Test &gt; Windows &gt; Test Explorer. The Test Explorer window will show inside Visual Studio, and your test should be visible (if they're not, try building your project to kick off the test discovery process). &lt;/p&gt;

&lt;p&gt;If you click the Run All link in the Test Explorer window, it will run your tests and show you success and failure. You can click on an individual test result to get failure information as well as stack trace information:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/test-dotnet-core-vs-runner.png" alt="VS test runner" /&gt;&lt;/p&gt;

&lt;h3&gt;ReSharper&lt;/h3&gt;

&lt;p&gt;ReSharper does not have test runner support for .Net Core yet. &lt;/p&gt;

&lt;h3&gt;NCrunch&lt;/h3&gt;

&lt;p&gt;NCrunch does not have test runner support for .Net Core yet. Remco Mulder, NCrunch's creator, has a useful explanation &lt;a href="https://ncrunch.uservoice.com/forums/245203-feature-requests/suggestions/8065623-support-dnx-projects"&gt;here&lt;/a&gt; on the difficulties that tool vendors face with the ongoing changes to tooling.&lt;/p&gt;

&lt;h2&gt;Test Frameworks&lt;/h2&gt;

&lt;h3&gt;xUnit&lt;/h3&gt;

&lt;p&gt;xUnit has beta support for .Net Core. In your project.json, you need to set the &lt;code&gt;testRunner&lt;/code&gt; to &lt;code&gt;xunit&lt;/code&gt; and add dependencies for xUnit and the dotnet-test-xunit console runner.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"testRunner": "xunit",
"dependencies": {
    "xunit": "2.2.0-beta2-build3300",
    "dotnet-test-xunit": "2.2.0-preview2-build1029"
},
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using the NuGet Package Management Console:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Install-Package xunit -Pre
Install-Package dotnet-test-xunit -Pre
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;NUnit&lt;/h3&gt;

&lt;p&gt;NUnit also has beta support for .Net Core. In your project.json, you need to set the &lt;code&gt;testRunner&lt;/code&gt; to &lt;code&gt;nunit&lt;/code&gt; and add dependencies for NUnit and the dotnet-test-nunit console runner.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"testRunner": "nunit",
"dependencies": {
    "NUnit": "3.4.1",
    "dotnet-test-nunit": "3.4.0-beta-1"
},
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using the NuGet Package Management Console:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Install-Package Nunit
Install-Package dotnet-test-nunit -Pre
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;MsTest&lt;/h3&gt;

&lt;p&gt;Microsoft's own MsTest also has support for .Net Core. In your project.json, you need to set the &lt;code&gt;testRunner&lt;/code&gt; to &lt;code&gt;mstest&lt;/code&gt; and add dependencies for MSTest.TestFramework and the dotnet-test-mstest console runner.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"testRunner": "mstest",
"dependencies": {
    "MSTest.TestFramework": "1.0.0-preview",
    "dotnet-test-mstest": "1.0.1-preview"
},
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using the NuGet Package Management Console:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Install-Package MSTest.TestFramework -Pre
Install-Package dotnet-test-mstest -Pre
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;BDDfy&lt;/h3&gt;

&lt;p&gt;BDDfy, from TestStack - the simplest BDD framework to use, customize and extend - has full support for .Net Core.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Install-Package TestStack.BDDfy
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Fixie&lt;/h3&gt;

&lt;p&gt;As described in the &lt;a href="https://github.com/fixie/fixie/wiki"&gt;Project Roadmap&lt;/a&gt;, Fixie 2.x is being actively developed on the dev branch to support .NET Core. Fixie itself should leverage .NET Core, and it should allow testing of projects that leverage .NET Core. &lt;/p&gt;

&lt;p&gt;For more detailed progress and discussion on .NET Core, see &lt;a href="https://github.com/fixie/fixie/issues/145"&gt;Issue #145 - Support .NET Core&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;One of the items on the roadmap is to publish a prerelease NuGet package of 2.x for initial round of feedback but, as far as I can tell, that has not been released yet.&lt;/p&gt;

&lt;p&gt;Fixie's creator, &lt;a href="https://twitter.com/plioi"&gt;Patrick Lioi&lt;/a&gt;, has more details on Fixie 2.0's progress on his &lt;a href="https://lostechies.com/patricklioi/2016/07/22/tiny-steps-creating-fixie-2-0/"&gt;blog&lt;/a&gt;, including a link to a &lt;a href="https://vimeo.com/175828748"&gt;video presentation&lt;/a&gt; he did about it.&lt;/p&gt;

&lt;h2&gt;Mocking Frameworks&lt;/h2&gt;

&lt;p&gt;Most of the mocking frameworks depend on Castle.Core, which itself currently has alpha support for .Net Core. Note, that at the time of writing, Castle.Core had a dependency on System.Diagnostics.TraceSource, meaning the mocking frameworks also had this dependency. As Jonathon Rossi says in the comments below, Castle.Core have since released Castle Core 4.0.0-beta001, which removes that dependency, so expect this dependency to drop off the mocking frameworks once they update to the latest Castle.Core.&lt;/p&gt;

&lt;h3&gt;NSubstitute&lt;/h3&gt;

&lt;p&gt;If you go to nuget.org, you will find that the latest NSubstitute package is version 1.10.0 from March and does not have support for .Net Core. However, there is actually an unlisted beta package of version 2.0 with support for .Net Core that is published to nuget.org and just not visible. &lt;/p&gt;

&lt;p&gt;You can install the package via the NuGet CLI with the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Install-Package NSubstitute -Version 2.0.0-beta -Pre
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or you can just add these references to the dependencies node of your project.json. Note that you also need to add a reference to System.Diagnostics.TraceSource.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"NSubstitute": "2.0.0-alpha003",
"System.Diagnostics.TraceSource": "4.0.0",
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can follow the progress of NSubstitute 2.0 on this &lt;a href="https://github.com/nsubstitute/NSubstitute/pull/197"&gt;GitHub issue&lt;/a&gt; or on &lt;a href="https://github.com/alexandrnikitin/NSubstitute/commits/Issue192_NetCore_Project"&gt;Alexandr Nikitin's branch&lt;/a&gt;. &lt;/p&gt;

&lt;h3&gt;FakeItEasy&lt;/h3&gt;

&lt;p&gt;FakeItEasy also don't have a package with .Net Core support officially published on NuGet, but you can access the alpha version of v2.3, with support for .Net Core, on an appveyor NuGet feed:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;https://ci.appveyor.com/nuget/fakeiteasy-jeremymeng
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To access this from your solution, just add this reference as a NuGet package source in Visual Studio and add a NuGet.config to the root of your solution like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;?xml version="1.0" encoding="utf-8"?&amp;gt;
&amp;lt;configuration&amp;gt;
  &amp;lt;packageSources&amp;gt;
    &amp;lt;add key="api.nuget.org" value="https://api.nuget.org/v3/index.json" /&amp;gt;
    &amp;lt;add key="appveyor FakeItEasy" value="https://ci.appveyor.com/nuget/fakeiteasy-jeremymeng" /&amp;gt;
  &amp;lt;/packageSources&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And add a reference to the latest version (2.2.0-coreclr-alpha30 at the time of writing) in the dependencies node of project.json.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"FakeItEasy": "2.2.0-coreclr-alpha30",
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can follow the progress of this release on this &lt;a href="https://github.com/FakeItEasy/FakeItEasy/issues/531"&gt;GitHub issues page&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;Moq&lt;/h3&gt;

&lt;p&gt;Moq has an alpha release published to NuGet.org with support for .Net Core:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Install-Package Moq -Pre
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And, like NSubstitute, it seems you also need to add a reference to System.Diagnostics.TraceSource in your project.json. You can read more about that on &lt;a href="http://stackoverflow.com/questions/37288385/moq-netcore-failing-for-net-core-rc2"&gt;stack overflow&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"moq.netcore": "4.6.25-alpha",
"System.Diagnostics.TraceSource": "4.0.0"
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Assertion Frameworks&lt;/h2&gt;

&lt;p&gt;&lt;a href="http://www.fluentassertions.com/"&gt;Fluent Assertions&lt;/a&gt; and &lt;a href="https://shouldly.readthedocs.io/en/latest/"&gt;Shouldly&lt;/a&gt; both have full support for .Net Core.&lt;/p&gt;

&lt;h2&gt;Other Testing Libraries&lt;/h2&gt;

&lt;p&gt;As far as I can tell, &lt;a href="http://approvaltests.com/"&gt;ApprovalTests&lt;/a&gt; does not have support for .Net Core yet.&lt;/p&gt;

&lt;h2&gt;Summary&lt;/h2&gt;

&lt;p&gt;.Net Core 1.0 has been officially released but the tooling is still in preview. This means that a number of open source testing libraries have been able to release at least alpha support for .Net Core, but it is not always easy to locate. In this post, I have looked at the main .Net testing providers, their current support for .Net Core, and how you can get hold of them.&lt;/p&gt;
</content></entry><entry><id>http://www.michael-whelan.net/replacing-appdomain-in-dotnet-core/</id><title type="text">Replacing AppDomain in .Net Core</title><summary type="html">&lt;p&gt;In the move to .Net Core, Microsoft decided to discontinue certain technologies because they were deemed to be problematic. AppDomain was one of those that did not make the cut. While AppDomains have been discontinued, some of their functionality is still being provided. It is quite hard to find those features though, as they are spread across multiple NuGet packages and there is very little documentation at this stage. Issues on github are the best source of information, but there has been a high churn of APIs in this area and a lot of those discussions and APIs are out-of-date. If you have been hunting around for these features then I hope the code samples here will at least provide you with a good starting point and some clues as to where to find related features.&lt;/p&gt;

</summary><published>2016-07-07T07:00:00Z</published><updated>2016-07-07T07:00:00Z</updated><link rel="alternate" href="http://www.michael-whelan.net/replacing-appdomain-in-dotnet-core/" /><content type="html">&lt;p&gt;In the move to .Net Core, Microsoft decided to discontinue certain technologies because they were deemed to be problematic. AppDomain was one of those that did not make the cut. While AppDomains have been discontinued, some of their functionality is still being provided. It is quite hard to find those features though, as they are spread across multiple NuGet packages and there is very little documentation at this stage. Issues on github are the best source of information, but there has been a high churn of APIs in this area and a lot of those discussions and APIs are out-of-date. If you have been hunting around for these features then I hope the code samples here will at least provide you with a good starting point and some clues as to where to find related features.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;h2&gt;Replacing AppDomain Unload event&lt;/h2&gt;

&lt;p&gt;In .Net classic, it could be quite useful to run code in the AppDomain Unload event, especially if you wanted to perform some actions after all of your tests had completed.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;System.AppDomain.CurrentDomain.DomainUnload += (sender, e) =&amp;gt; {
    InvokeBatchProcessors();
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are no AppDomains in .Net Core. Instead, we can use the AssemblyLoadContext, which is part of the System.Runtime.Loader library:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;System.Runtime.Loader.AssemblyLoadContext.Default.Unloading += context =&amp;gt; InvokeBatchProcessors();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At the time of writing, the current version of System.Runtime.Loader package is 4.0, which you include in your project.json with this entry.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"System.Runtime.Loader": "4.0.0",   
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Replacing AppDomain.GetAssemblies&lt;/h2&gt;

&lt;p&gt;In .Net classic, you could get all of the referenced assemblies from AppDomain.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;AppDomain.CurrentDomain.GetAssemblies();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I really struggled to figure out how to do this in .Net Core. Up until RC1, you were able to use the LibraryManager from the Microsoft.Extensions.PlatformAbstractions package to do it, but that functionality was either removed or moved somewhere else for RC2. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;return libraryManager.GetReferencingLibraries("Specify")
    .SelectMany(a =&amp;gt; a.Assemblies)
    .Select(Assembly.Load);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;One way to do it now, is with the DependencyContext from the Microsoft.Extensions.DependencyModel package. You have to load each assembly and use the new AssemblyName class. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static IEnumerable&amp;lt;Assembly&amp;gt; GetReferencingAssemblies(string assemblyName)
{
    var assemblies = new List&amp;lt;Assembly&amp;gt;();
    var dependencies = DependencyContext.Default.RuntimeLibraries;
    foreach (var library in dependencies)
    {
        if (IsCandidateLibrary(library, assemblyName))
        {
            var assembly = Assembly.Load(new AssemblyName(library.Name));
            assemblies.Add(assembly);
        }
    }
    return assemblies;
}

private static bool IsCandidateLibrary(RuntimeLibrary library, assemblyName)
{
    return library.Name == (assemblyName)
        || library.Dependencies.Any(d =&amp;gt; d.Name.StartsWith(assemblyName));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The DependencyContext.Default has two properties, RuntimeLibraries and CompileLibraries, which both appear to provide the same list of libraries. I'm sure there is a difference between them but at this stage I am not sure what that difference is.&lt;/p&gt;

&lt;p&gt;The current version of Microsoft.Extensions.DependencyModel is 1.0:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"Microsoft.Extensions.DependencyModel": "1.0.0"
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Get All Types from AppDomain&lt;/h2&gt;

&lt;p&gt;If you were getting all the assemblies from the AppDomain, chances are you were wanting to retrieve the types in those assemblies matching a certain query. Using an AppDomain, you could do that like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;return AppDomain.CurrentDomain
    .GetAssemblies()
    .SelectMany(assembly =&amp;gt; assembly.GetExportedTypes());
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It is pretty similar with .Net Core. Again, using the Microsoft.Extensions.DependencyModel library and the GetReferencingAssemblies method from the previous example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;return GetReferencingLibraries("Specify")
    .SelectMany(assembly =&amp;gt; assembly.ExportedTypes);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Assembly now has an ExportedTypes method instead of GetExportedTypes.&lt;/p&gt;

&lt;h2&gt;Creating a Polyfill&lt;/h2&gt;

&lt;p&gt;As I described in my &lt;a href="http://www.michael-whelan.net/porting-dotnet-framework-library-to-dotnet-core/"&gt;previous post&lt;/a&gt;, when porting your code to .Net Core you might like to include a polyfill for missing functionality, so that your code can interact with both implementations seamlessly. A polyfill for AppDomain.CurrentDomain.GetAssemblies would look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class AppDomain
{
    public static AppDomain CurrentDomain { get; private set; }

    static AppDomain()
    {
        CurrentDomain = new AppDomain();
    }

    public Assembly[] GetAssemblies()
    {
        var assemblies = new List&amp;lt;Assembly&amp;gt;();
        var dependencies = DependencyContext.Default.RuntimeLibraries;
        foreach (var library in dependencies)
        {
            if (IsCandidateCompilationLibrary(library))
            {
                var assembly = Assembly.Load(new AssemblyName(library.Name));
                assemblies.Add(assembly);
            }
        }
        return assemblies.ToArray();
    }

    private static bool IsCandidateCompilationLibrary(RuntimeLibrary compilationLibrary)
    {
        return compilationLibrary.Name == ("Specify")
            || compilationLibrary.Dependencies.Any(d =&amp;gt; d.Name.StartsWith("Specify"));
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Summary&lt;/h2&gt;

&lt;p&gt;While AppDomains have been discontinued, for the time being at least, some of their functionality is still being provided. It is quite hard to find those features as they are spread across multiple NuGet packages and there is very little documentation at this stage. Issues on github are the best source of information, but there has been a high churn of APIs in this area and a lot of those discussions and APIs are out-of-date. If you have been hunting around for these features then I hope the code samples here will at least provide you with a good starting point and some clues as to where to find related features.&lt;/p&gt;
</content></entry><entry><id>http://www.michael-whelan.net/porting-dotnet-framework-library-to-dotnet-core/</id><title type="text">Porting a .Net Framework Library to .Net Core</title><summary type="html">&lt;p&gt;I have recently been involved with porting a couple of open source frameworks to .Net Core. It's a brave new world, with lots of new things to discover and learn. In this post I am going to outline the process I've followed to convert my code and a few of the things I've learned along the way. Hopefully, this post will shed some light on the process if you are looking to port your .Net Framework code to .Net Core. Special thanks to &lt;a href="https://twitter.com/JakeGinnivan"&gt;Jake Ginnivan&lt;/a&gt; who, as always, was a font of knowledge on all things programming during the porting exercises!&lt;/p&gt;

</summary><published>2016-07-04T07:00:00Z</published><updated>2016-07-04T07:00:00Z</updated><link rel="alternate" href="http://www.michael-whelan.net/porting-dotnet-framework-library-to-dotnet-core/" /><content type="html">&lt;p&gt;I have recently been involved with porting a couple of open source frameworks to .Net Core. It's a brave new world, with lots of new things to discover and learn. In this post I am going to outline the process I've followed to convert my code and a few of the things I've learned along the way. Hopefully, this post will shed some light on the process if you are looking to port your .Net Framework code to .Net Core. Special thanks to &lt;a href="https://twitter.com/JakeGinnivan"&gt;Jake Ginnivan&lt;/a&gt; who, as always, was a font of knowledge on all things programming during the porting exercises!&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;h2&gt;Run the .Net Portability Analyzer&lt;/h2&gt;

&lt;p&gt;Before you even attempt to port your library, you should run the &lt;a href="https://visualstudiogallery.msdn.microsoft.com/1177943e-cfb7-4822-a8a6-e56c7905292b"&gt;.Net Portability Analyzer&lt;/a&gt; on your existing project. This is available as a console application or a Visual Studio plugin. You can access the Visual Studio plugin by right clicking on the project and selecting Analyze -&gt; Analyze Assembly Portability.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/portcore-analyzer-run.png" alt="Run .Net Portability Analyzer" /&gt;&lt;/p&gt;

&lt;p&gt;This will produce a report that provides two useful pieces of information:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;High-level summary&lt;/strong&gt;: The summary gives you a percentage for each of your assemblies, telling you how much of your framework usage is portable to .NET Core. &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;List of non-portable APIs&lt;/strong&gt;: It provides a table that lists all the usages of APIs that aren’t portable. Most usefully, it also includes a list of recommended changes.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/portcore-analyzer-results.png" alt=".Net Portability Analyzer results" /&gt;&lt;/p&gt;

&lt;h2&gt;Run I Can Has .Net Core&lt;/h2&gt;

&lt;p&gt;Another useful analysis tool is the &lt;a href="https://icanhasdot.net/"&gt;I Can Has .Net Core website&lt;/a&gt;. Just upload your project's packages.config, project.json or paket.dependencies files for analysis and it will build a visualisation of the packages and whether .NET Standard versions are available on nuget.org.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/portcore-icanhasdotnetcore.jpg" alt="I Can Has .Net Core" /&gt;&lt;/p&gt;

&lt;h2&gt;Create a new .Net Core class library project&lt;/h2&gt;

&lt;p&gt;The way to "upgrade" a .Net framework project is actually to create a new .Net Core class library and copy the old C# files into it. Assuming you want it to have the same name as the old project, and be in the same folder, you should remove the existing project and rename its folder on the file system so that the new project can be saved to the original location. &lt;/p&gt;

&lt;h2&gt;Add a global.json file&lt;/h2&gt;

&lt;p&gt;You will need to add a &lt;a href="https://docs.microsoft.com/en-us/dotnet/articles/core/tools/global-json"&gt;global.json file&lt;/a&gt; to the solution, which is used to configure the solution as a whole. It includes just two sections, projects and sdk by default.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  "projects": [ "app", "tests" ],
    "sdk": { "version": "1.0.0-preview2-003121" }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The projects property designates which folders contain source code for the solution. The sdk property specifies the version of the DNX (.Net Execution Environment) that Visual Studio will use when opening the solution. (I think DNX might no longer be the correct terminology. .Net Core has been an ever moving target).&lt;/p&gt;

&lt;h2&gt;Add target frameworks to project.json file&lt;/h2&gt;

&lt;p&gt;The frameworks node in project.json specifies the framework versions that the project should be compiled against. In this example, the library will support .Net 4 (net40) and .Net Standard 1.5 (netstandard1.5). Because .Net Core has been decomposed into many modules, this allows you to specify the additional NuGet package dependencies that .Net Core needs (shown in the netstandard1.5 node below).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  "version": "1.0.0-*", 
  "dependencies": {
    "LibLog": "4.2.5",
    "TestStack.BDDfy": "4.3.0"
  },
    "frameworks": {
        "net40": {
          "dependencies": {

          },
            "frameworkAssemblies": {
                "System.Runtime.Serialization": "4.0.0.0",
                "System.Xml": "4.0.0.0"
            }
        },
        "netstandard1.5": {
            "imports": "dnxcore50",
            "buildOptions": {
              "define": [
                "LIBLOG_PORTABLE",
                "NETSTANDARD1_5"
              ]
            },
          "dependencies": {
            "NETStandard.Library": "1.6.0",
            "Microsoft.CSharp": "4.0.1",
            "System.Dynamic.Runtime": "4.0.11"
          }
      }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Fixing missing references for .Net Core&lt;/h2&gt;

&lt;p&gt;When you first build the project, you will most likely get a lot of missing reference exceptions for the .Net Standard target framework (see image below). Note that the project is specified as [ProjectName].NetStandard, Version 1.5. &lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/portcore-missing-references.png" alt="Run .Net Portability Analyzer" /&gt;&lt;/p&gt;

&lt;p&gt;This is quite easy to resolve if this functionality has been ported to one of the many new .Net Core packages. The &lt;a href="http://packagesearch.azurewebsites.net/"&gt;Reverse Package Search&lt;/a&gt; website is a great tool for finding NuGet packages that contain different types. For example, searching for the missing DynamicAttribute from the above error returns the System.Dynamic.Runtime NuGet package. This just needs to be added to the list of dependencies under the netstandard node to resolve the missing reference exception.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/portcore-package-search.png" alt="Run .Net Portability Analyzer" /&gt;&lt;/p&gt;

&lt;h2&gt;GetTypeInfo&lt;/h2&gt;

&lt;p&gt;One of the most common issues is that a lot of the old System.Type reflection functionality has moved to TypeInfo in .Net Core, which you can access through the GetTypeInfo extension method on Type.&lt;/p&gt;

&lt;p&gt;So, instead of &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var members = obj.GetType().GetMembers();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;you would now use:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System.Reflection;
var members = obj.GetType().GetTypeInfo().GetMembers(); 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I am sure that more elegant solutions will come out in time, but for now the way I am handling these differences is with compiler directives. What I have found effective is to create a TypeExtensions class with extension methods on Type. There I replace the various Type properties with methods of the same name, with separate implementations of each method for each supported framework. This, at least, constrains the compiler directives to one place, rather than doing it for every method, and leaves the production code free of compiler directives.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#if NET40
    public static class TypeExtensions
    {
        public static Assembly Assembly(this Type type)
        {
            return type.Assembly;
        }

        public static bool IsValueType(this Type type)
        {
            return type.IsValueType;
        }
    }
#else
    using System.Linq;
    public static class TypeExtensions
    {
        public static Assembly Assembly(this Type type)
        {
            return type.GetTypeInfo().Assembly;   
        }

        public static bool IsValueType(this Type type)
        {
            return type.GetTypeInfo().IsValueType;
        }
    }
#endif
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So, instead of calling the Reflection property, my code now calls my extension method with the same name. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// type.IsValueType;
type.IsValueType();
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Compiler directives or rewrite code&lt;/h2&gt;

&lt;p&gt;It is not ideal to have too many compiler directives in your code. When a feature you were using in the old framework has not been ported to .Net Core you have a choice to make&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Write a new solution for .Net Core and switch between the old and new implementations with compiler directives, or&lt;/li&gt;
&lt;li&gt;Replace the original implementation with a new one that works for both frameworks  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For example, I had some JSON serialization functionality that relied on the JavaScriptSerializer in the System.Web library. This serializer has not been ported to .Net Core, so the short term fix - to get things working - was to use compiler directives to keep the existing soluiton for .Net 4 and provide a new solution for .Net Core. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#if NET40
    using System.Web.Script.Serialization;  
    public class JsonSerializer : ISerializer
    {
        public string Serialize(object obj)
        {
            var serializer = new JavaScriptSerializer();
            string json = serializer.Serialize(obj);

            return new JsonFormatter(json).Format();
        }
    }
#else
    using Newtonsoft.Json;
    public class JsonSerializer : ISerializer
    {
        public string Serialize(object obj)
        {
            return JsonConvert.SerializeObject(obj, Formatting.Indented,
                new JsonSerializerSettings
                {
                    NullValueHandling = NullValueHandling.Ignore,
                    ReferenceLoopHandling = ReferenceLoopHandling.Ignore
                });
        }
    }
#endif
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As more things get ported to .Net Core though, ideally I would hope to remove compiler directives and have a single solution that works for both frameworks, because it really is not ideal to maintain multiple implementations of lots of functionality throughout a codebase. &lt;/p&gt;

&lt;p&gt;Thankfully, the DataContractJsonSerializer has been ported to the System.Runtime.Serialization.Json NuGet package, so I can actually have a single solution that is supported by both frameworks and remove the compiler directives.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System.Runtime.Serialization.Json;
public class JsonSerializer : ISerializer
{
    public string Serialize(object obj)
    {
        var serializer = new DataContractJsonSerializer(obj.GetType());
        string json;
        using (var stream = new MemoryStream())
        {
            serializer.WriteObject(stream, obj);
            json = Encoding.UTF8.GetString(stream.ToArray());
        }

        return new JsonFormatter(json).Format();
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Why didn't I just use Json.Net or ServiceStack.Text to serialize Json? Well, I would if I was building an application, but for a NuGet library I don't want to add a NuGet dependency just for one class of functionality. That might be old world thinking though, given how much of the .Net Framework is now provided as NuGet packages. I may just change my thinking on that but, for now, I still see a distinction between third party packages and .Net packages.&lt;/p&gt;

&lt;h2&gt;Backwards-compatible Polyfills&lt;/h2&gt;

&lt;p&gt;Credit to Jake Ginnivan for this solution. It is actually pretty easy to satisfy the compiler by providing polyfills, or shims, for types that have not been ported to .Net Core. &lt;/p&gt;

&lt;p&gt;For example, Serialization has not been ported, but you might have classes with the Serializable attribute on them. Providing an empty SerializableAttribute class in the System.Runtime.Serialization namespace will satisfy the compiler for your .Net Core code.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#if !NET40
namespace System.Runtime.Serialization
{
    public class SerializableAttribute : Attribute
    {
    }
}
#endif 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Another example I have come across is a polyfill for AppDomain.CurrentDomain, now that AppDomains are no longer supported in .Net Core.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private sealed class AppDomain
{
    public static AppDomain CurrentDomain { get; private set; }

    static AppDomain()
    {
        CurrentDomain = new AppDomain();
    }

    public List&amp;lt;Assembly&amp;gt; GetAssemblies()
    {
        ... // .Net Core functionality here
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Summary&lt;/h2&gt;

&lt;p&gt;There are a lot of exciting new things to learn with .Net Core. Porting your existing code to the framework is a little bit of work - but not too much. The process is quite straightforward with predictable steps, most of which I've hopefully communicated here. The .Net Portability Analyzer is a huge help in enabling you to plan out the conversion beforehand, providing you with a list of issues and - most helpfully - even the solutions to most of the issues. The main area of concern is to provide new solutions for areas of the code that rely on parts of the .Net Framework that have not been ported. Thankfully, this seems to be a reasonably small surface area though, of course, it will depend on each application.&lt;/p&gt;
</content></entry><entry><id>http://www.michael-whelan.net/github-cvs-resumes/</id><title type="text">GitHub CVs / Resumes</title><summary type="html">&lt;p&gt;I just discovered that Github can automatically generate a CV/resume for its users based on the public information in their GitHub account. You have to opt-in by going to their &lt;a href="https://github.com/resume/resume.github.com"&gt;GitHub project&lt;/a&gt; page and starring the project. Check out mine at &lt;a href="http://resume.github.com/?mwhelan"&gt;http://resume.github.com/?mwhelan&lt;/a&gt;. What a clever idea!&lt;/p&gt;

</summary><published>2016-06-02T07:00:00Z</published><updated>2016-06-02T07:00:00Z</updated><link rel="alternate" href="http://www.michael-whelan.net/github-cvs-resumes/" /><content type="html">&lt;p&gt;I just discovered that Github can automatically generate a CV/resume for its users based on the public information in their GitHub account. You have to opt-in by going to their &lt;a href="https://github.com/resume/resume.github.com"&gt;GitHub project&lt;/a&gt; page and starring the project. Check out mine at &lt;a href="http://resume.github.com/?mwhelan"&gt;http://resume.github.com/?mwhelan&lt;/a&gt;. What a clever idea!&lt;/p&gt;

&lt;!--excerpt--&gt;
</content></entry><entry><id>http://www.michael-whelan.net/become-a-fullstack-dotnet-developer-review/</id><title type="text">Review of Pluralsight's Become a Full-stack .Net Developer</title><summary type="html">&lt;p&gt;This weekend was a long weekend in the UK, and my wife was away, so I took the opportunity to work through &lt;a href="http://programmingwithmosh.com/"&gt;Mosh Hamedani's&lt;/a&gt; comprehensive 3 part course on Pluralsight, titled &lt;code&gt;Become a Full-stack .Net Developer&lt;/code&gt;. The three part series aims to take you from a junior .Net developer through to a senior .Net developer by building an ASP.Net MVC 5 application with Entity Framework 6. I really enjoyed the course and thought I would provide a review of it.&lt;/p&gt;

</summary><published>2016-05-30T09:00:00Z</published><updated>2016-05-30T09:00:00Z</updated><link rel="alternate" href="http://www.michael-whelan.net/become-a-fullstack-dotnet-developer-review/" /><content type="html">&lt;p&gt;This weekend was a long weekend in the UK, and my wife was away, so I took the opportunity to work through &lt;a href="http://programmingwithmosh.com/"&gt;Mosh Hamedani's&lt;/a&gt; comprehensive 3 part course on Pluralsight, titled &lt;code&gt;Become a Full-stack .Net Developer&lt;/code&gt;. The three part series aims to take you from a junior .Net developer through to a senior .Net developer by building an ASP.Net MVC 5 application with Entity Framework 6. I really enjoyed the course and thought I would provide a review of it.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;The series is a whopping 14 hours in total, which is really, really long by Pluralsight standards. I would really recommend watching it though and will probably make it suggested watching for my dev teams.&lt;/p&gt;

&lt;p&gt;I did intend to build out the whole thing while I watched but I abandoned that as it would have taken too long (though I would recommend doing that if you are a little less experienced). I revved up the speed to double and watched it like a movie. That's still 7 hours of watching, but well worth it.&lt;/p&gt;

&lt;p&gt;According to Mosh, the series is aimed at the following audiences&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Part 1 =&amp;gt; junior developer
Part 2 =&amp;gt; moving from junior developer to intermediate developer
Part 3 =&amp;gt; moving from intermediate developer to senior developer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hearing that, a lot of experienced devs might move right along, but I'd encourage you to look a bit deeper. While the content is geared towards ASP.Net MVC 5 and Entity Framework 6, the most valuable takeaway is the approach of a senior developer. &lt;/p&gt;

&lt;p&gt;What impressed me the most was Mosh's discipline. He did not let himself get distracted by going off to google to research better solutions, but consistently stuck to the task at hand, OK with doing it a bit dirty at first, confident that with an iterative approach to development he would quickly circle back and remove any technical debt. I can be far less disciplined and find it so easy to get sidetracked on to some research or other yak shaving activity. There's so much to be said for completing the task!&lt;/p&gt;

&lt;p&gt;My favourite part was the third and final part, which gets into architecture and automated testing and such, two topics close to my heart. But the first two are really good value as well. In fact, if Mosh didn't tell you they were aimed at the 3 levels you wouldn't know the difference. It's just that he starts off doing ugly things like newing up the DbContext directly in the controller so that he doesn't distract you with too many concepts at once. But slowly but surely, he refactors things until eventually you have a pretty clean architecture, with repositories/unit of work, and programming to interfaces that are injected with your IoC container. &lt;/p&gt;

&lt;p&gt;The style of the course is similar to pairing with an experienced developer who is just commentating on what he is doing and why. He shows a number of productivity tools, such as ReSharper, Web Essentials and the Productivity Power Tools. In particular, he shows a number of ReSharper shortcuts. Unfortunately, he uses the older IntelliJ shortcuts and I use the Visual Studio ones, but it was no problem to look up their Visual Studio counterparts on &lt;a href="https://www.jetbrains.com/help/resharper/2016.1/Reference__Keyboard_Shortcuts.html"&gt;their website&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;You can view the courses &lt;a href="http://app.pluralsight.com/author/mosh-hamedani"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;You can currently get 6 months of Pluralsight for free if you sign up for an &lt;a href="https://www.visualstudio.com/en-us/products/visual-studio-dev-essentials-vs.aspx"&gt;MSDN Dev Essentials&lt;/a&gt; subscription.&lt;/p&gt;

&lt;p&gt;I think Mosh is a really talented teacher and his style and focus on quality is quite distinctive from other teachers. I can also recommend some of his &lt;a href="https://www.udemy.com/user/moshfeghhamedani/"&gt;Udemy courses&lt;/a&gt; that I've done. You can also find him on his &lt;a href="https://www.youtube.com/channel/UCWv7vMbMWH4-V0ZXdmDpPBA"&gt;youtube channel&lt;/a&gt;.&lt;/p&gt;
</content></entry><entry><id>http://www.michael-whelan.net/bdd-course-london/</id><title type="text">BDD Course in London</title><summary type="html">&lt;p&gt;Last week I had the pleasure of attending Gaspar Nagy's 3-day &lt;a href="http://gasparnagy.com/trainings/specflow/"&gt;BDD course&lt;/a&gt; at Skills Matter's &lt;a href="https://skillsmatter.com/event-space"&gt;CodeNode&lt;/a&gt; in London. I have been doing BDD for over 5 years now, and SpecFlow is not my preferred .Net BDD tool, but I still got a huge amount of value out of the course. Gaspar is very knowledgeable about BDD and I would highly recommend the course, whether you are new to BDD,  a &lt;a href="http://www.specsolutions.eu/news/bddaddict"&gt;BDD addict&lt;/a&gt; like me, or even if you are just struggling with agile.&lt;/p&gt;

</summary><published>2016-05-27T09:00:00Z</published><updated>2016-05-27T09:00:00Z</updated><link rel="alternate" href="http://www.michael-whelan.net/bdd-course-london/" /><content type="html">&lt;p&gt;Last week I had the pleasure of attending Gaspar Nagy's 3-day &lt;a href="http://gasparnagy.com/trainings/specflow/"&gt;BDD course&lt;/a&gt; at Skills Matter's &lt;a href="https://skillsmatter.com/event-space"&gt;CodeNode&lt;/a&gt; in London. I have been doing BDD for over 5 years now, and SpecFlow is not my preferred .Net BDD tool, but I still got a huge amount of value out of the course. Gaspar is very knowledgeable about BDD and I would highly recommend the course, whether you are new to BDD,  a &lt;a href="http://www.specsolutions.eu/news/bddaddict"&gt;BDD addict&lt;/a&gt; like me, or even if you are just struggling with agile.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;I had the good fortune of choosing a seat next to &lt;a href="https://twitter.com/QuestMasterNET"&gt;Dirk Rombauts&lt;/a&gt; on the first day, which resulted in two days of great pair programming, where I learned a lot, including some excellent pairing habits and one trick to double my ReSharper ninja skills!&lt;/p&gt;

&lt;p&gt;It is a wide-ranging course that covers how to gather examples and then turn them into executable specifications, with the implementation focused on ASP.Net MVC and WPF .Net projects. The course covers refining and documenting specification workshop results in Gherkin, feeding Gherkin scenarios into acceptance test driven development with SpecFlow, and advanced concepts for automation and building living documentation systems. The course topics are discussed through examples, demos and hands-on exercises to ensure knowledge that can be used in practice.&lt;/p&gt;

&lt;p&gt;The course started off by looking at the four different areas that make up BDD. So many companies that I see struggling with agile tend to focus primarily on the agile project management area, with perhaps one or two other techniques from the other areas. I think you need to do all four to maximise the benefits of agile.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://www.michael-whelan.net/images/specflow-bdd.png" alt="BDD" /&gt;&lt;/p&gt;

&lt;p&gt;The first day was focused on capturing specification workshop results in gherkin, and covered some theory:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Agile testing is not about hunting criminals (finding bugs after development) but more like crime prevention.&lt;/li&gt;
&lt;li&gt;As formality increases, tests and requirements become indistinguishable. At the limit, tests and requirements are equivalent. &lt;em&gt;Equivalence Hypothesis (Martin, Melnik)&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The second day looked at SpecFlow core concepts and ATDD basics, with examples using a WPF pomodoro application, including:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Introduction to the Acceptance Test Driven Development workflow (test first, outside-in)&lt;/li&gt;
&lt;li&gt;Core concepts for (A)TDD: mocking, stubbing, dependency injection&lt;/li&gt;
&lt;li&gt;Domain layer automation (automating under the skin)&lt;/li&gt;
&lt;li&gt;Organizing step definitions&lt;/li&gt;
&lt;li&gt;Sharing state between steps&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The third day looked at advanced test automation topics, using an ASP.Net MVC pomodoro application, including:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Clean and maintainable automation layer&lt;/li&gt;
&lt;li&gt;Dealing with external dependencies&lt;/li&gt;
&lt;li&gt;Flickering scenarios&lt;/li&gt;
&lt;li&gt;UI layer automation (MVC ASP.NET, Driver, PageObject pattern)&lt;/li&gt;
&lt;li&gt;Handling the database&lt;/li&gt;
&lt;li&gt;Challenges of out-of-process testing (with Selenium)&lt;/li&gt;
&lt;li&gt;Organizing step definitions&lt;/li&gt;
&lt;li&gt;Defaults and implicit assumptions of scenarios&lt;/li&gt;
&lt;li&gt;Automapper and SpecFlow.Assist&lt;/li&gt;
&lt;li&gt;Putting it all together: implement new functionality with BDD&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Step Definitions&lt;/h2&gt;

&lt;p&gt;I've spoken with SpecFlow developers who are struggling to organise their step definitions, and I haven't really known what to advise, as it's not an issue with BDDfy, so I was interested to see the best tips for organising them. Gaspar showed a lot of great techniques for organising feature files and step definitions. I particularly liked the suggestion of moving user stories into a feature tree after the sprint was completed. &lt;/p&gt;

&lt;p&gt;I can't help feeling that step definitions are the wrong abstraction for reusability in an automated testing project. There are inherent difficulties from wanting to reuse steps when the two use cases are slightly different, and I would prefer to avoid it altogether.&lt;/p&gt;

&lt;p&gt;Stepping back from tools for a moment, I think that step definitions are just metadata that should just read whatever way makes the most sense for a particular scenario in the living documentation that the users will see, whether it is exactly the same as other steps in the system or slightly different. While I recognise the importance and value of the DRY principle, I don't think it needs to be applied to the step definition itself (as it's just a string on a report).&lt;/p&gt;

&lt;p&gt;What should be reusable is the code inside the step definitions. Things like repositories, builders/object mothers in the Given steps, drivers in the When step, assertions in the Then steps. Why do you need to reuse steps if they only have one line of code, and if that line itself is a useful and reusable abstraction?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public void Given_I_have_5_customers()
{
    Database.Save(CustomerBuilder.CreateListOfSize(5).BuildList());
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Generally, I'm just not comfortable with having my scenario being distributed across multiple feature and step definition files, which I think is inherent in the Gherkin-based approach. I prefer the pure C# solution of having the entire scenario in one file with the class-per-scenario approach (and no feature file):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class ValidEditStudentDetailsScenario : ScenarioFor&amp;lt;MvcControllerDriver, StudentEditStory&amp;gt;
{
    private Student _student;
    private ControllerResultTest&amp;lt;StudentController&amp;gt; _result;

    public void Given_I_am_editing_an_existing_student_with_valid_data()
    {
        Builder&amp;lt;Student&amp;gt;.CreateNew().Persist();
        _student = Container
            .Get&amp;lt;IStudentRepository&amp;gt;()
            .FindById(1);
        _student.FirstMidName = "newFirstName";
    }
    public void When_I_save_the_changes()
    {
        _result = SUT.ExecuteActionFor&amp;lt;StudentController&amp;gt;(c =&amp;gt; c.Edit(_student));
    }

    public void Then_I_am_returned_to_the_student_list()
    {
        _result.ShouldRedirectTo&amp;lt;StudentController&amp;gt;(c =&amp;gt; c.Index(null, null, null, null));
    }

    public void AndThen_the_changes_have_been_saved()
    {
        Container.Get&amp;lt;IStudentRepository&amp;gt;()
            .FindById(1)
            .ShouldBeEquivalentTo(_student);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;The driver pattern&lt;/h2&gt;

&lt;p&gt;Speaking of drivers, Gaspar gave an excellent talk on the driver pattern in relation to the &lt;a href="http://alistair.cockburn.us/Hexagonal+architecture"&gt;hexagonal architecture&lt;/a&gt;. I am quite familiar with how the &lt;a href="http://martinfowler.com/eaaDev/WindowDriver.html"&gt;window driver pattern&lt;/a&gt; is applied to Selenium, in the form of page objects, but Gaspar articulated a more general purpose pattern which extends beyond the UI/windows. &lt;/p&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;There is a lot more I could say about the course. I'm still digesting a lot of the excellent information. My recommendation would be to try to attend it yourself (there are a number of venues around Europe). BDD is by far the best way to deliver software on agile projects that I have come across, and Gaspar Nagy is an excellent guide.&lt;/p&gt;
</content></entry><entry><id>http://www.michael-whelan.net/code-compiling-but-resharper-red/</id><title type="text">Code compiling but ReSharper is red</title><summary type="html">&lt;p&gt;From time-to-time, I have this weird situation with ReSharper and Visual Studios (different versions of both) where my code is compiling, but ReSharper is highlighting some things in red. I think there might be a few different solutions to this problem, and I'll add others here if I come across them. The solution that worked for me this time is just to &lt;a href="http://stackoverflow.com/questions/6040338/everything-compiles-but-resharper-marks-everything-in-red"&gt;delete the .suo files&lt;/a&gt;.&lt;/p&gt;

</summary><published>2015-06-19T09:00:00Z</published><updated>2015-06-19T09:00:00Z</updated><link rel="alternate" href="http://www.michael-whelan.net/code-compiling-but-resharper-red/" /><content type="html">&lt;p&gt;From time-to-time, I have this weird situation with ReSharper and Visual Studios (different versions of both) where my code is compiling, but ReSharper is highlighting some things in red. I think there might be a few different solutions to this problem, and I'll add others here if I come across them. The solution that worked for me this time is just to &lt;a href="http://stackoverflow.com/questions/6040338/everything-compiles-but-resharper-marks-everything-in-red"&gt;delete the .suo files&lt;/a&gt;.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;Another solution that has worked in the past is to clear the ReSharper cache and restart Visual Studio. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ReSharper &amp;gt; Options &amp;gt; Environment &amp;gt; General &amp;gt; Options &amp;gt; General 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Click the Clear Caches button.&lt;/p&gt;
</content></entry></feed>